{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "import ipynb.fs.full.Seismic_Parameters as my\n",
    "importlib.reload(my)\n",
    "df = pd.read_csv(\"../../../data/1st_part.csv\")\n",
    "n=25\n",
    "from ipynb.fs.full.Seismic_Parameters import time,m_mean,e_mean,a_and_b,Msd,md,low_and_high,ct_and_c,yyy,Msd1\n",
    "Time = time(df,n)\n",
    "M_mean = m_mean(df,n)\n",
    "E_mean = e_mean(df,n)\n",
    "a,b = a_and_b(df,n)\n",
    "msd = Msd1(df,n,a,b)\n",
    "MD = md(df,n)\n",
    "lowest_mag,highest_mag = low_and_high(df,n)\n",
    "ct,c = ct_and_c(df,n)\n",
    "y = yyy(df,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectors to numpy array to df to csv\n",
    "#df.to_csv('C:/Users/HP/Downloads/1st_part.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>M_mean</th>\n",
       "      <th>E_mean</th>\n",
       "      <th>b</th>\n",
       "      <th>a</th>\n",
       "      <th>msd</th>\n",
       "      <th>MD</th>\n",
       "      <th>CT</th>\n",
       "      <th>c</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2306</td>\n",
       "      <td>113.9</td>\n",
       "      <td>4.225230e+07</td>\n",
       "      <td>0.444127</td>\n",
       "      <td>0.983267</td>\n",
       "      <td>0.153094</td>\n",
       "      <td>4.086067</td>\n",
       "      <td>646.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2249</td>\n",
       "      <td>114.1</td>\n",
       "      <td>4.349634e+07</td>\n",
       "      <td>0.448990</td>\n",
       "      <td>0.980977</td>\n",
       "      <td>0.171512</td>\n",
       "      <td>4.115147</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2570</td>\n",
       "      <td>114.4</td>\n",
       "      <td>3.841575e+07</td>\n",
       "      <td>0.466053</td>\n",
       "      <td>0.971782</td>\n",
       "      <td>0.213324</td>\n",
       "      <td>4.214867</td>\n",
       "      <td>1104.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2354</td>\n",
       "      <td>114.1</td>\n",
       "      <td>4.171167e+07</td>\n",
       "      <td>0.445595</td>\n",
       "      <td>0.974578</td>\n",
       "      <td>0.100399</td>\n",
       "      <td>4.112863</td>\n",
       "      <td>1128.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2331</td>\n",
       "      <td>113.6</td>\n",
       "      <td>4.156783e+07</td>\n",
       "      <td>0.425835</td>\n",
       "      <td>0.980193</td>\n",
       "      <td>0.134908</td>\n",
       "      <td>3.998188</td>\n",
       "      <td>1138.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2165</td>\n",
       "      <td>120.6</td>\n",
       "      <td>5.371605e+07</td>\n",
       "      <td>0.559495</td>\n",
       "      <td>0.958170</td>\n",
       "      <td>0.261169</td>\n",
       "      <td>4.187436</td>\n",
       "      <td>1929.666667</td>\n",
       "      <td>3897.874014</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2165</td>\n",
       "      <td>120.8</td>\n",
       "      <td>5.401805e+07</td>\n",
       "      <td>0.568851</td>\n",
       "      <td>0.955369</td>\n",
       "      <td>0.282634</td>\n",
       "      <td>4.220528</td>\n",
       "      <td>1930.000000</td>\n",
       "      <td>3898.303627</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2171</td>\n",
       "      <td>121.5</td>\n",
       "      <td>5.590742e+07</td>\n",
       "      <td>0.575559</td>\n",
       "      <td>0.960317</td>\n",
       "      <td>0.343963</td>\n",
       "      <td>4.231506</td>\n",
       "      <td>1973.333333</td>\n",
       "      <td>3984.242005</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2194</td>\n",
       "      <td>122.1</td>\n",
       "      <td>5.663489e+07</td>\n",
       "      <td>0.595710</td>\n",
       "      <td>0.960081</td>\n",
       "      <td>0.345654</td>\n",
       "      <td>4.288340</td>\n",
       "      <td>1997.333333</td>\n",
       "      <td>4031.790498</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2272</td>\n",
       "      <td>122.8</td>\n",
       "      <td>5.606965e+07</td>\n",
       "      <td>0.638131</td>\n",
       "      <td>0.934147</td>\n",
       "      <td>0.502123</td>\n",
       "      <td>4.436120</td>\n",
       "      <td>2076.333333</td>\n",
       "      <td>4188.378017</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time  M_mean        E_mean         b         a       msd        MD  \\\n",
       "0    2306   113.9  4.225230e+07  0.444127  0.983267  0.153094  4.086067   \n",
       "1    2249   114.1  4.349634e+07  0.448990  0.980977  0.171512  4.115147   \n",
       "2    2570   114.4  3.841575e+07  0.466053  0.971782  0.213324  4.214867   \n",
       "3    2354   114.1  4.171167e+07  0.445595  0.974578  0.100399  4.112863   \n",
       "4    2331   113.6  4.156783e+07  0.425835  0.980193  0.134908  3.998188   \n",
       "..    ...     ...           ...       ...       ...       ...       ...   \n",
       "132  2165   120.6  5.371605e+07  0.559495  0.958170  0.261169  4.187436   \n",
       "133  2165   120.8  5.401805e+07  0.568851  0.955369  0.282634  4.220528   \n",
       "134  2171   121.5  5.590742e+07  0.575559  0.960317  0.343963  4.231506   \n",
       "135  2194   122.1  5.663489e+07  0.595710  0.960081  0.345654  4.288340   \n",
       "136  2272   122.8  5.606965e+07  0.638131  0.934147  0.502123  4.436120   \n",
       "\n",
       "              CT            c    y  \n",
       "0     646.000000     0.000000  4.3  \n",
       "1     682.000000     0.000000  4.6  \n",
       "2    1104.000000     0.000000  4.0  \n",
       "3    1128.000000     0.000000  4.1  \n",
       "4    1138.000000     0.000000  4.4  \n",
       "..           ...          ...  ...  \n",
       "132  1929.666667  3897.874014  4.6  \n",
       "133  1930.000000  3898.303627  5.2  \n",
       "134  1973.333333  3984.242005  5.0  \n",
       "135  1997.333333  4031.790498  5.0  \n",
       "136  2076.333333  4188.378017  5.7  \n",
       "\n",
       "[137 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred_dict={'Time':Time,'M_mean':M_mean,'E_mean':E_mean,'b':b,'a':a,'msd':msd,'MD':MD,'CT':ct,'c':c,'y':y}\n",
    "new_df = pd.DataFrame(x_pred_dict)\n",
    "new_df = new_df.iloc[:-1 , :]\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "target = new_df['y']\n",
    "# features = df1.drop(['mag','time','magType'],axis=1)\n",
    "features = new_df[['Time','M_mean','E_mean','b','a','msd','MD','CT','c']]\n",
    "target = target.to_numpy()\n",
    "features = np.array(features)\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, \n",
    "                                                                            target, \n",
    "                                                                            test_size=0.33, \n",
    "                                                                            random_state=0)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "train_features[:, :] = sc.fit_transform(train_features[:, :])\n",
    "test_features[:, :] = sc.transform(test_features[:, :])\n",
    "train_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=128*2, activation='tanh', input_shape=(train_features.shape[1],)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=64*2, activation='tanh'))\n",
    "\n",
    "# Add fully connected layer with no activation function\n",
    "network.add(layers.Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile neural network\n",
    "network.compile(loss='mse', # Mean squared error\n",
    "                optimizer='RMSprop', # Optimization algorithm\n",
    "                metrics=['mse','mae']) # Mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 91 samples, validate on 46 samples\n",
      "Epoch 1/495\n",
      "91/91 [==============================] - 2s 20ms/sample - loss: 22.3264 - mse: 22.3264 - mae: 4.6956 - val_loss: 18.9474 - val_mse: 18.9474 - val_mae: 4.2837\n",
      "Epoch 2/495\n",
      "91/91 [==============================] - 0s 253us/sample - loss: 21.1365 - mse: 21.1365 - mae: 4.5268 - val_loss: 18.8814 - val_mse: 18.8814 - val_mae: 4.2818\n",
      "Epoch 3/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 20.2488 - mse: 20.2488 - mae: 4.4369 - val_loss: 16.9778 - val_mse: 16.9778 - val_mae: 4.0744\n",
      "Epoch 4/495\n",
      "91/91 [==============================] - 0s 317us/sample - loss: 19.0444 - mse: 19.0444 - mae: 4.3130 - val_loss: 16.7241 - val_mse: 16.7241 - val_mae: 4.0290\n",
      "Epoch 5/495\n",
      "91/91 [==============================] - 0s 252us/sample - loss: 18.0095 - mse: 18.0095 - mae: 4.1923 - val_loss: 15.0444 - val_mse: 15.0444 - val_mae: 3.8342\n",
      "Epoch 6/495\n",
      "91/91 [==============================] - 0s 241us/sample - loss: 17.0173 - mse: 17.0173 - mae: 4.0734 - val_loss: 14.7593 - val_mse: 14.7593 - val_mae: 3.7688\n",
      "Epoch 7/495\n",
      "91/91 [==============================] - 0s 294us/sample - loss: 15.9151 - mse: 15.9151 - mae: 3.9283 - val_loss: 13.0472 - val_mse: 13.0472 - val_mae: 3.5659\n",
      "Epoch 8/495\n",
      "91/91 [==============================] - 0s 236us/sample - loss: 14.7620 - mse: 14.7620 - mae: 3.7920 - val_loss: 12.4819 - val_mse: 12.4819 - val_mae: 3.4640\n",
      "Epoch 9/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 13.5854 - mse: 13.5854 - mae: 3.6286 - val_loss: 10.9359 - val_mse: 10.9359 - val_mae: 3.2507\n",
      "Epoch 10/495\n",
      "91/91 [==============================] - 0s 253us/sample - loss: 12.4126 - mse: 12.4126 - mae: 3.4672 - val_loss: 10.3208 - val_mse: 10.3208 - val_mae: 3.1295\n",
      "Epoch 11/495\n",
      "91/91 [==============================] - 0s 214us/sample - loss: 11.2483 - mse: 11.2483 - mae: 3.2879 - val_loss: 8.8127 - val_mse: 8.8127 - val_mae: 2.8901\n",
      "Epoch 12/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 10.1283 - mse: 10.1283 - mae: 3.1081 - val_loss: 8.4091 - val_mse: 8.4091 - val_mae: 2.7797\n",
      "Epoch 13/495\n",
      "91/91 [==============================] - 0s 248us/sample - loss: 9.0667 - mse: 9.0667 - mae: 2.9204 - val_loss: 6.8999 - val_mse: 6.8999 - val_mae: 2.5070\n",
      "Epoch 14/495\n",
      "91/91 [==============================] - 0s 273us/sample - loss: 8.0852 - mse: 8.0852 - mae: 2.7325 - val_loss: 6.7103 - val_mse: 6.7103 - val_mae: 2.4212\n",
      "Epoch 15/495\n",
      "91/91 [==============================] - 0s 283us/sample - loss: 7.1319 - mse: 7.1319 - mae: 2.5458 - val_loss: 5.2286 - val_mse: 5.2286 - val_mae: 2.1495\n",
      "Epoch 16/495\n",
      "91/91 [==============================] - 0s 252us/sample - loss: 6.2136 - mse: 6.2136 - mae: 2.3565 - val_loss: 5.0149 - val_mse: 5.0149 - val_mae: 2.0464\n",
      "Epoch 17/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 5.3295 - mse: 5.3295 - mae: 2.1696 - val_loss: 3.7784 - val_mse: 3.7784 - val_mae: 1.8035\n",
      "Epoch 18/495\n",
      "91/91 [==============================] - 0s 273us/sample - loss: 4.5308 - mse: 4.5308 - mae: 1.9817 - val_loss: 3.5901 - val_mse: 3.5901 - val_mae: 1.6737\n",
      "Epoch 19/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 3.8135 - mse: 3.8135 - mae: 1.7973 - val_loss: 2.6379 - val_mse: 2.6379 - val_mae: 1.4759\n",
      "Epoch 20/495\n",
      "91/91 [==============================] - 0s 352us/sample - loss: 3.1973 - mse: 3.1973 - mae: 1.6234 - val_loss: 2.5559 - val_mse: 2.5559 - val_mae: 1.3230\n",
      "Epoch 21/495\n",
      "91/91 [==============================] - 0s 351us/sample - loss: 2.6674 - mse: 2.6674 - mae: 1.4419 - val_loss: 1.8239 - val_mse: 1.8239 - val_mae: 1.1765\n",
      "Epoch 22/495\n",
      "91/91 [==============================] - 0s 329us/sample - loss: 2.2327 - mse: 2.2327 - mae: 1.2991 - val_loss: 1.8712 - val_mse: 1.8712 - val_mae: 1.0215\n",
      "Epoch 23/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 1.8727 - mse: 1.8727 - mae: 1.1244 - val_loss: 1.3041 - val_mse: 1.3041 - val_mae: 0.9556\n",
      "Epoch 24/495\n",
      "91/91 [==============================] - 0s 269us/sample - loss: 1.5877 - mse: 1.5877 - mae: 1.0570 - val_loss: 1.4285 - val_mse: 1.4285 - val_mae: 0.8292\n",
      "Epoch 25/495\n",
      "91/91 [==============================] - 0s 298us/sample - loss: 1.3492 - mse: 1.3492 - mae: 0.8820 - val_loss: 0.9855 - val_mse: 0.9855 - val_mae: 0.8123\n",
      "Epoch 26/495\n",
      "91/91 [==============================] - 0s 242us/sample - loss: 1.1575 - mse: 1.1575 - mae: 0.8856 - val_loss: 1.1150 - val_mse: 1.1150 - val_mae: 0.7232\n",
      "Epoch 27/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.9927 - mse: 0.9927 - mae: 0.7284 - val_loss: 0.7853 - val_mse: 0.7853 - val_mae: 0.7022\n",
      "Epoch 28/495\n",
      "91/91 [==============================] - 0s 320us/sample - loss: 0.8633 - mse: 0.8633 - mae: 0.7529 - val_loss: 0.9018 - val_mse: 0.9018 - val_mae: 0.6668\n",
      "Epoch 29/495\n",
      "91/91 [==============================] - 0s 252us/sample - loss: 0.7577 - mse: 0.7577 - mae: 0.6428 - val_loss: 0.6741 - val_mse: 0.6741 - val_mae: 0.6278\n",
      "Epoch 30/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.6819 - mse: 0.6819 - mae: 0.6594 - val_loss: 0.7838 - val_mse: 0.7838 - val_mae: 0.6469\n",
      "Epoch 31/495\n",
      "91/91 [==============================] - 0s 373us/sample - loss: 0.6244 - mse: 0.6244 - mae: 0.6013 - val_loss: 0.6279 - val_mse: 0.6279 - val_mae: 0.5988\n",
      "Epoch 32/495\n",
      "91/91 [==============================] - 0s 324us/sample - loss: 0.5882 - mse: 0.5882 - mae: 0.6082 - val_loss: 0.7339 - val_mse: 0.7339 - val_mae: 0.6526\n",
      "Epoch 33/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.5622 - mse: 0.5622 - mae: 0.5878 - val_loss: 0.6198 - val_mse: 0.6198 - val_mae: 0.5821\n",
      "Epoch 34/495\n",
      "91/91 [==============================] - 0s 339us/sample - loss: 0.5503 - mse: 0.5503 - mae: 0.5876 - val_loss: 0.7209 - val_mse: 0.7209 - val_mae: 0.6682\n",
      "Epoch 35/495\n",
      "91/91 [==============================] - 0s 333us/sample - loss: 0.5409 - mse: 0.5409 - mae: 0.5877 - val_loss: 0.6277 - val_mse: 0.6277 - val_mae: 0.5779\n",
      "Epoch 36/495\n",
      "91/91 [==============================] - 0s 352us/sample - loss: 0.5400 - mse: 0.5400 - mae: 0.5797 - val_loss: 0.7182 - val_mse: 0.7182 - val_mae: 0.6784\n",
      "Epoch 37/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.5350 - mse: 0.5350 - mae: 0.5912 - val_loss: 0.6330 - val_mse: 0.6330 - val_mae: 0.5786\n",
      "Epoch 38/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.5343 - mse: 0.5343 - mae: 0.5734 - val_loss: 0.7067 - val_mse: 0.7067 - val_mae: 0.6773\n",
      "Epoch 39/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.5256 - mse: 0.5256 - mae: 0.5889 - val_loss: 0.6259 - val_mse: 0.6259 - val_mae: 0.5756\n",
      "Epoch 40/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.5198 - mse: 0.5198 - mae: 0.5627 - val_loss: 0.6828 - val_mse: 0.6828 - val_mae: 0.6662\n",
      "Epoch 41/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.5079 - mse: 0.5079 - mae: 0.5792 - val_loss: 0.6110 - val_mse: 0.6110 - val_mae: 0.5711\n",
      "Epoch 42/495\n",
      "91/91 [==============================] - 0s 283us/sample - loss: 0.4993 - mse: 0.4993 - mae: 0.5499 - val_loss: 0.6563 - val_mse: 0.6563 - val_mae: 0.6498\n",
      "Epoch 43/495\n",
      "91/91 [==============================] - 0s 317us/sample - loss: 0.4898 - mse: 0.4898 - mae: 0.5685 - val_loss: 0.5997 - val_mse: 0.5997 - val_mae: 0.5747\n",
      "Epoch 44/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.4825 - mse: 0.4825 - mae: 0.5401 - val_loss: 0.6362 - val_mse: 0.6362 - val_mae: 0.6409\n",
      "Epoch 45/495\n",
      "91/91 [==============================] - 0s 291us/sample - loss: 0.4801 - mse: 0.4801 - mae: 0.5621 - val_loss: 0.5969 - val_mse: 0.5969 - val_mae: 0.5888\n",
      "Epoch 46/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.4738 - mse: 0.4738 - mae: 0.5356 - val_loss: 0.6188 - val_mse: 0.6188 - val_mae: 0.6357\n",
      "Epoch 47/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.4774 - mse: 0.4774 - mae: 0.5576 - val_loss: 0.5911 - val_mse: 0.5911 - val_mae: 0.5979\n",
      "Epoch 48/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.4633 - mse: 0.4633 - mae: 0.5322 - val_loss: 0.5837 - val_mse: 0.5837 - val_mae: 0.6193\n",
      "Epoch 49/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.4628 - mse: 0.4628 - mae: 0.5433 - val_loss: 0.5638 - val_mse: 0.5638 - val_mae: 0.5902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.4342 - mse: 0.4342 - mae: 0.5170 - val_loss: 0.5242 - val_mse: 0.5242 - val_mae: 0.5839\n",
      "Epoch 51/495\n",
      "91/91 [==============================] - 0s 266us/sample - loss: 0.4264 - mse: 0.4264 - mae: 0.5221 - val_loss: 0.5300 - val_mse: 0.5300 - val_mae: 0.5788\n",
      "Epoch 52/495\n",
      "91/91 [==============================] - 0s 323us/sample - loss: 0.3994 - mse: 0.3994 - mae: 0.4911 - val_loss: 0.4709 - val_mse: 0.4709 - val_mae: 0.5530\n",
      "Epoch 53/495\n",
      "91/91 [==============================] - 0s 310us/sample - loss: 0.4019 - mse: 0.4019 - mae: 0.5131 - val_loss: 0.5461 - val_mse: 0.5461 - val_mae: 0.6141\n",
      "Epoch 54/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.4118 - mse: 0.4118 - mae: 0.4922 - val_loss: 0.4929 - val_mse: 0.4929 - val_mae: 0.5509\n",
      "Epoch 55/495\n",
      "91/91 [==============================] - 0s 313us/sample - loss: 0.4711 - mse: 0.4711 - mae: 0.5659 - val_loss: 0.7058 - val_mse: 0.7058 - val_mae: 0.7108\n",
      "Epoch 56/495\n",
      "91/91 [==============================] - 0s 295us/sample - loss: 0.5593 - mse: 0.5593 - mae: 0.5954 - val_loss: 0.5980 - val_mse: 0.5980 - val_mae: 0.5868\n",
      "Epoch 57/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.5957 - mse: 0.5957 - mae: 0.6251 - val_loss: 0.7120 - val_mse: 0.7120 - val_mae: 0.6924\n",
      "Epoch 58/495\n",
      "91/91 [==============================] - 0s 339us/sample - loss: 0.5511 - mse: 0.5511 - mae: 0.6096 - val_loss: 0.5221 - val_mse: 0.5221 - val_mae: 0.5299\n",
      "Epoch 59/495\n",
      "91/91 [==============================] - 0s 284us/sample - loss: 0.4759 - mse: 0.4759 - mae: 0.5397 - val_loss: 0.5636 - val_mse: 0.5636 - val_mae: 0.6054\n",
      "Epoch 60/495\n",
      "91/91 [==============================] - 0s 308us/sample - loss: 0.4176 - mse: 0.4176 - mae: 0.5293 - val_loss: 0.4773 - val_mse: 0.4773 - val_mae: 0.5063\n",
      "Epoch 61/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.3976 - mse: 0.3976 - mae: 0.4827 - val_loss: 0.5254 - val_mse: 0.5254 - val_mae: 0.5790\n",
      "Epoch 62/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.3942 - mse: 0.3942 - mae: 0.5108 - val_loss: 0.5086 - val_mse: 0.5086 - val_mae: 0.5469\n",
      "Epoch 63/495\n",
      "91/91 [==============================] - 0s 304us/sample - loss: 0.4094 - mse: 0.4094 - mae: 0.4927 - val_loss: 0.5546 - val_mse: 0.5546 - val_mae: 0.5996\n",
      "Epoch 64/495\n",
      "91/91 [==============================] - 0s 289us/sample - loss: 0.4313 - mse: 0.4313 - mae: 0.5371 - val_loss: 0.5502 - val_mse: 0.5502 - val_mae: 0.5908\n",
      "Epoch 65/495\n",
      "91/91 [==============================] - 0s 269us/sample - loss: 0.4396 - mse: 0.4396 - mae: 0.5157 - val_loss: 0.5607 - val_mse: 0.5607 - val_mae: 0.6037\n",
      "Epoch 66/495\n",
      "91/91 [==============================] - 0s 289us/sample - loss: 0.4425 - mse: 0.4425 - mae: 0.5441 - val_loss: 0.5256 - val_mse: 0.5256 - val_mae: 0.5789\n",
      "Epoch 67/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.4148 - mse: 0.4148 - mae: 0.4995 - val_loss: 0.5087 - val_mse: 0.5087 - val_mae: 0.5713\n",
      "Epoch 68/495\n",
      "91/91 [==============================] - 0s 323us/sample - loss: 0.3947 - mse: 0.3947 - mae: 0.5159 - val_loss: 0.4697 - val_mse: 0.4697 - val_mae: 0.5389\n",
      "Epoch 69/495\n",
      "91/91 [==============================] - 0s 295us/sample - loss: 0.3653 - mse: 0.3653 - mae: 0.4637 - val_loss: 0.4653 - val_mse: 0.4653 - val_mae: 0.5408\n",
      "Epoch 70/495\n",
      "91/91 [==============================] - 0s 270us/sample - loss: 0.3514 - mse: 0.3514 - mae: 0.4867 - val_loss: 0.4373 - val_mse: 0.4373 - val_mae: 0.5115\n",
      "Epoch 71/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.3404 - mse: 0.3404 - mae: 0.4445 - val_loss: 0.4613 - val_mse: 0.4613 - val_mae: 0.5338\n",
      "Epoch 72/495\n",
      "91/91 [==============================] - 0s 290us/sample - loss: 0.3416 - mse: 0.3416 - mae: 0.4775 - val_loss: 0.4382 - val_mse: 0.4382 - val_mae: 0.5087\n",
      "Epoch 73/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.3501 - mse: 0.3501 - mae: 0.4507 - val_loss: 0.4997 - val_mse: 0.4997 - val_mae: 0.5560\n",
      "Epoch 74/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.3676 - mse: 0.3676 - mae: 0.4955 - val_loss: 0.4676 - val_mse: 0.4676 - val_mae: 0.5286\n",
      "Epoch 75/495\n",
      "91/91 [==============================] - 0s 308us/sample - loss: 0.3926 - mse: 0.3926 - mae: 0.4776 - val_loss: 0.5576 - val_mse: 0.5576 - val_mae: 0.5909\n",
      "Epoch 76/495\n",
      "91/91 [==============================] - 0s 284us/sample - loss: 0.4115 - mse: 0.4115 - mae: 0.5324 - val_loss: 0.4804 - val_mse: 0.4804 - val_mae: 0.5350\n",
      "Epoch 77/495\n",
      "91/91 [==============================] - 0s 294us/sample - loss: 0.4211 - mse: 0.4211 - mae: 0.5034 - val_loss: 0.5525 - val_mse: 0.5525 - val_mae: 0.5881\n",
      "Epoch 78/495\n",
      "91/91 [==============================] - 0s 329us/sample - loss: 0.4041 - mse: 0.4041 - mae: 0.5273 - val_loss: 0.4283 - val_mse: 0.4283 - val_mae: 0.4994\n",
      "Epoch 79/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.3780 - mse: 0.3780 - mae: 0.4794 - val_loss: 0.4873 - val_mse: 0.4873 - val_mae: 0.5452\n",
      "Epoch 80/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.3457 - mse: 0.3457 - mae: 0.4810 - val_loss: 0.3687 - val_mse: 0.3687 - val_mae: 0.4554\n",
      "Epoch 81/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.3208 - mse: 0.3208 - mae: 0.4411 - val_loss: 0.4411 - val_mse: 0.4411 - val_mae: 0.5121\n",
      "Epoch 82/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.3037 - mse: 0.3037 - mae: 0.4444 - val_loss: 0.3365 - val_mse: 0.3365 - val_mae: 0.4300\n",
      "Epoch 83/495\n",
      "91/91 [==============================] - 0s 263us/sample - loss: 0.2957 - mse: 0.2957 - mae: 0.4260 - val_loss: 0.4417 - val_mse: 0.4417 - val_mae: 0.5209\n",
      "Epoch 84/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.3009 - mse: 0.3009 - mae: 0.4381 - val_loss: 0.3391 - val_mse: 0.3391 - val_mae: 0.4389\n",
      "Epoch 85/495\n",
      "91/91 [==============================] - 0s 314us/sample - loss: 0.3235 - mse: 0.3235 - mae: 0.4609 - val_loss: 0.5413 - val_mse: 0.5413 - val_mae: 0.6124\n",
      "Epoch 86/495\n",
      "91/91 [==============================] - 0s 310us/sample - loss: 0.3862 - mse: 0.3862 - mae: 0.4915 - val_loss: 0.4493 - val_mse: 0.4493 - val_mae: 0.5625\n",
      "Epoch 87/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.4699 - mse: 0.4699 - mae: 0.5636 - val_loss: 0.6693 - val_mse: 0.6693 - val_mae: 0.6816\n",
      "Epoch 88/495\n",
      "91/91 [==============================] - 0s 286us/sample - loss: 0.5053 - mse: 0.5053 - mae: 0.5642 - val_loss: 0.4740 - val_mse: 0.4740 - val_mae: 0.5769\n",
      "Epoch 89/495\n",
      "91/91 [==============================] - 0s 302us/sample - loss: 0.4592 - mse: 0.4592 - mae: 0.5492 - val_loss: 0.5047 - val_mse: 0.5047 - val_mae: 0.5837\n",
      "Epoch 90/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.3627 - mse: 0.3627 - mae: 0.4771 - val_loss: 0.3827 - val_mse: 0.3827 - val_mae: 0.4965\n",
      "Epoch 91/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.3170 - mse: 0.3170 - mae: 0.4656 - val_loss: 0.4033 - val_mse: 0.4033 - val_mae: 0.5123\n",
      "Epoch 92/495\n",
      "91/91 [==============================] - 0s 292us/sample - loss: 0.2875 - mse: 0.2875 - mae: 0.4130 - val_loss: 0.3910 - val_mse: 0.3910 - val_mae: 0.4896\n",
      "Epoch 93/495\n",
      "91/91 [==============================] - 0s 340us/sample - loss: 0.2923 - mse: 0.2923 - mae: 0.4469 - val_loss: 0.4115 - val_mse: 0.4115 - val_mae: 0.5155\n",
      "Epoch 94/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.3144 - mse: 0.3144 - mae: 0.4248 - val_loss: 0.4944 - val_mse: 0.4944 - val_mae: 0.5536\n",
      "Epoch 95/495\n",
      "91/91 [==============================] - 0s 292us/sample - loss: 0.3613 - mse: 0.3613 - mae: 0.4985 - val_loss: 0.4939 - val_mse: 0.4939 - val_mae: 0.5706\n",
      "Epoch 96/495\n",
      "91/91 [==============================] - 0s 325us/sample - loss: 0.4147 - mse: 0.4147 - mae: 0.4988 - val_loss: 0.5966 - val_mse: 0.5966 - val_mae: 0.6196\n",
      "Epoch 97/495\n",
      "91/91 [==============================] - 0s 319us/sample - loss: 0.4380 - mse: 0.4380 - mae: 0.5527 - val_loss: 0.4819 - val_mse: 0.4819 - val_mae: 0.5624\n",
      "Epoch 98/495\n",
      "91/91 [==============================] - 0s 303us/sample - loss: 0.4157 - mse: 0.4157 - mae: 0.5036 - val_loss: 0.5128 - val_mse: 0.5128 - val_mae: 0.5664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.3630 - mse: 0.3630 - mae: 0.4998 - val_loss: 0.3830 - val_mse: 0.3830 - val_mae: 0.4917\n",
      "Epoch 100/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.3151 - mse: 0.3151 - mae: 0.4294 - val_loss: 0.4168 - val_mse: 0.4168 - val_mae: 0.4962\n",
      "Epoch 101/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.2810 - mse: 0.2810 - mae: 0.4339 - val_loss: 0.3353 - val_mse: 0.3353 - val_mae: 0.4496\n",
      "Epoch 102/495\n",
      "91/91 [==============================] - 0s 348us/sample - loss: 0.2607 - mse: 0.2607 - mae: 0.3835 - val_loss: 0.3802 - val_mse: 0.3802 - val_mae: 0.4676\n",
      "Epoch 103/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.2506 - mse: 0.2506 - mae: 0.4082 - val_loss: 0.3279 - val_mse: 0.3279 - val_mae: 0.4442\n",
      "Epoch 104/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.2481 - mse: 0.2481 - mae: 0.3716 - val_loss: 0.3822 - val_mse: 0.3822 - val_mae: 0.4722\n",
      "Epoch 105/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.2531 - mse: 0.2531 - mae: 0.4128 - val_loss: 0.3504 - val_mse: 0.3504 - val_mae: 0.4656\n",
      "Epoch 106/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.2656 - mse: 0.2656 - mae: 0.3855 - val_loss: 0.4211 - val_mse: 0.4211 - val_mae: 0.5093\n",
      "Epoch 107/495\n",
      "91/91 [==============================] - 0s 295us/sample - loss: 0.2896 - mse: 0.2896 - mae: 0.4478 - val_loss: 0.4205 - val_mse: 0.4205 - val_mae: 0.5297\n",
      "Epoch 108/495\n",
      "91/91 [==============================] - 0s 286us/sample - loss: 0.3232 - mse: 0.3232 - mae: 0.4330 - val_loss: 0.5008 - val_mse: 0.5008 - val_mae: 0.5678\n",
      "Epoch 109/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.3696 - mse: 0.3696 - mae: 0.5087 - val_loss: 0.5187 - val_mse: 0.5187 - val_mae: 0.6058\n",
      "Epoch 110/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.3952 - mse: 0.3952 - mae: 0.4898 - val_loss: 0.5170 - val_mse: 0.5170 - val_mae: 0.5698\n",
      "Epoch 111/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.4043 - mse: 0.4043 - mae: 0.5288 - val_loss: 0.5087 - val_mse: 0.5087 - val_mae: 0.5984\n",
      "Epoch 112/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.3603 - mse: 0.3603 - mae: 0.4737 - val_loss: 0.4087 - val_mse: 0.4087 - val_mae: 0.4963\n",
      "Epoch 113/495\n",
      "91/91 [==============================] - 0s 287us/sample - loss: 0.3279 - mse: 0.3279 - mae: 0.4801 - val_loss: 0.4402 - val_mse: 0.4402 - val_mae: 0.5438\n",
      "Epoch 114/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.2850 - mse: 0.2850 - mae: 0.4142 - val_loss: 0.3317 - val_mse: 0.3317 - val_mae: 0.4456\n",
      "Epoch 115/495\n",
      "91/91 [==============================] - 0s 292us/sample - loss: 0.2625 - mse: 0.2625 - mae: 0.4277 - val_loss: 0.3963 - val_mse: 0.3963 - val_mae: 0.4989\n",
      "Epoch 116/495\n",
      "91/91 [==============================] - 0s 328us/sample - loss: 0.2453 - mse: 0.2453 - mae: 0.3781 - val_loss: 0.3061 - val_mse: 0.3061 - val_mae: 0.4382\n",
      "Epoch 117/495\n",
      "91/91 [==============================] - 0s 294us/sample - loss: 0.2473 - mse: 0.2473 - mae: 0.4128 - val_loss: 0.4282 - val_mse: 0.4282 - val_mae: 0.5084\n",
      "Epoch 118/495\n",
      "91/91 [==============================] - 0s 324us/sample - loss: 0.2666 - mse: 0.2666 - mae: 0.4034 - val_loss: 0.3417 - val_mse: 0.3417 - val_mae: 0.4728\n",
      "Epoch 119/495\n",
      "91/91 [==============================] - 0s 310us/sample - loss: 0.3197 - mse: 0.3197 - mae: 0.4639 - val_loss: 0.5898 - val_mse: 0.5898 - val_mae: 0.6238\n",
      "Epoch 120/495\n",
      "91/91 [==============================] - 0s 295us/sample - loss: 0.4076 - mse: 0.4076 - mae: 0.5160 - val_loss: 0.4337 - val_mse: 0.4337 - val_mae: 0.5313\n",
      "Epoch 121/495\n",
      "91/91 [==============================] - 0s 299us/sample - loss: 0.4474 - mse: 0.4474 - mae: 0.5561 - val_loss: 0.6016 - val_mse: 0.6016 - val_mae: 0.6204\n",
      "Epoch 122/495\n",
      "91/91 [==============================] - 0s 329us/sample - loss: 0.4208 - mse: 0.4208 - mae: 0.5295 - val_loss: 0.3643 - val_mse: 0.3643 - val_mae: 0.4837\n",
      "Epoch 123/495\n",
      "91/91 [==============================] - 0s 293us/sample - loss: 0.3362 - mse: 0.3362 - mae: 0.4617 - val_loss: 0.4425 - val_mse: 0.4425 - val_mae: 0.5026\n",
      "Epoch 124/495\n",
      "91/91 [==============================] - 0s 327us/sample - loss: 0.2838 - mse: 0.2838 - mae: 0.4357 - val_loss: 0.3222 - val_mse: 0.3222 - val_mae: 0.4377\n",
      "Epoch 125/495\n",
      "91/91 [==============================] - 0s 351us/sample - loss: 0.2530 - mse: 0.2530 - mae: 0.3835 - val_loss: 0.3848 - val_mse: 0.3848 - val_mae: 0.4657\n",
      "Epoch 126/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.2427 - mse: 0.2427 - mae: 0.3999 - val_loss: 0.3386 - val_mse: 0.3386 - val_mae: 0.4565\n",
      "Epoch 127/495\n",
      "91/91 [==============================] - 0s 314us/sample - loss: 0.2471 - mse: 0.2471 - mae: 0.3690 - val_loss: 0.3995 - val_mse: 0.3995 - val_mae: 0.4879\n",
      "Epoch 128/495\n",
      "91/91 [==============================] - 0s 339us/sample - loss: 0.2659 - mse: 0.2659 - mae: 0.4282 - val_loss: 0.4095 - val_mse: 0.4095 - val_mae: 0.5218\n",
      "Epoch 129/495\n",
      "91/91 [==============================] - 0s 335us/sample - loss: 0.2983 - mse: 0.2983 - mae: 0.4126 - val_loss: 0.4703 - val_mse: 0.4703 - val_mae: 0.5445\n",
      "Epoch 130/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.3414 - mse: 0.3414 - mae: 0.4901 - val_loss: 0.4917 - val_mse: 0.4917 - val_mae: 0.5860\n",
      "Epoch 131/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.3600 - mse: 0.3600 - mae: 0.4645 - val_loss: 0.4802 - val_mse: 0.4802 - val_mae: 0.5483\n",
      "Epoch 132/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.3578 - mse: 0.3578 - mae: 0.5010 - val_loss: 0.4516 - val_mse: 0.4516 - val_mae: 0.5554\n",
      "Epoch 133/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.3149 - mse: 0.3149 - mae: 0.4311 - val_loss: 0.3990 - val_mse: 0.3990 - val_mae: 0.4893\n",
      "Epoch 134/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.2836 - mse: 0.2836 - mae: 0.4445 - val_loss: 0.3848 - val_mse: 0.3848 - val_mae: 0.5053\n",
      "Epoch 135/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.2526 - mse: 0.2526 - mae: 0.3748 - val_loss: 0.3528 - val_mse: 0.3528 - val_mae: 0.4498\n",
      "Epoch 136/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.2380 - mse: 0.2380 - mae: 0.4041 - val_loss: 0.3566 - val_mse: 0.3566 - val_mae: 0.4804\n",
      "Epoch 137/495\n",
      "91/91 [==============================] - 0s 324us/sample - loss: 0.2287 - mse: 0.2287 - mae: 0.3497 - val_loss: 0.3489 - val_mse: 0.3489 - val_mae: 0.4397\n",
      "Epoch 138/495\n",
      "91/91 [==============================] - 0s 298us/sample - loss: 0.2288 - mse: 0.2288 - mae: 0.3939 - val_loss: 0.3570 - val_mse: 0.3570 - val_mae: 0.4811\n",
      "Epoch 139/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.2349 - mse: 0.2349 - mae: 0.3524 - val_loss: 0.3850 - val_mse: 0.3850 - val_mae: 0.4619\n",
      "Epoch 140/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.2512 - mse: 0.2512 - mae: 0.4119 - val_loss: 0.3869 - val_mse: 0.3869 - val_mae: 0.5014\n",
      "Epoch 141/495\n",
      "91/91 [==============================] - 0s 317us/sample - loss: 0.2792 - mse: 0.2792 - mae: 0.3950 - val_loss: 0.4791 - val_mse: 0.4791 - val_mae: 0.5291\n",
      "Epoch 142/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.3178 - mse: 0.3178 - mae: 0.4647 - val_loss: 0.4263 - val_mse: 0.4263 - val_mae: 0.5396\n",
      "Epoch 143/495\n",
      "91/91 [==============================] - 0s 302us/sample - loss: 0.3528 - mse: 0.3528 - mae: 0.4675 - val_loss: 0.5494 - val_mse: 0.5494 - val_mae: 0.5844\n",
      "Epoch 144/495\n",
      "91/91 [==============================] - 0s 264us/sample - loss: 0.3616 - mse: 0.3616 - mae: 0.5005 - val_loss: 0.3744 - val_mse: 0.3744 - val_mae: 0.4971\n",
      "Epoch 145/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.3383 - mse: 0.3383 - mae: 0.4661 - val_loss: 0.4909 - val_mse: 0.4909 - val_mae: 0.5359\n",
      "Epoch 146/495\n",
      "91/91 [==============================] - 0s 328us/sample - loss: 0.3058 - mse: 0.3058 - mae: 0.4580 - val_loss: 0.3163 - val_mse: 0.3163 - val_mae: 0.4315\n",
      "Epoch 147/495\n",
      "91/91 [==============================] - 0s 297us/sample - loss: 0.2776 - mse: 0.2776 - mae: 0.4165 - val_loss: 0.4506 - val_mse: 0.4506 - val_mae: 0.5273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/495\n",
      "91/91 [==============================] - 0s 322us/sample - loss: 0.2761 - mse: 0.2761 - mae: 0.4263 - val_loss: 0.3299 - val_mse: 0.3299 - val_mae: 0.4614\n",
      "Epoch 149/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.2871 - mse: 0.2871 - mae: 0.4399 - val_loss: 0.4830 - val_mse: 0.4830 - val_mae: 0.5516\n",
      "Epoch 150/495\n",
      "91/91 [==============================] - 0s 358us/sample - loss: 0.3073 - mse: 0.3073 - mae: 0.4428 - val_loss: 0.3673 - val_mse: 0.3673 - val_mae: 0.4992\n",
      "Epoch 151/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.3149 - mse: 0.3149 - mae: 0.4628 - val_loss: 0.4647 - val_mse: 0.4647 - val_mae: 0.5444\n",
      "Epoch 152/495\n",
      "91/91 [==============================] - 0s 317us/sample - loss: 0.2944 - mse: 0.2944 - mae: 0.4289 - val_loss: 0.3478 - val_mse: 0.3478 - val_mae: 0.4737\n",
      "Epoch 153/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.2727 - mse: 0.2727 - mae: 0.4346 - val_loss: 0.4003 - val_mse: 0.4003 - val_mae: 0.5058\n",
      "Epoch 154/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.2443 - mse: 0.2443 - mae: 0.3842 - val_loss: 0.3277 - val_mse: 0.3277 - val_mae: 0.4431\n",
      "Epoch 155/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.2319 - mse: 0.2319 - mae: 0.4054 - val_loss: 0.3660 - val_mse: 0.3660 - val_mae: 0.4831\n",
      "Epoch 156/495\n",
      "91/91 [==============================] - 0s 314us/sample - loss: 0.2230 - mse: 0.2230 - mae: 0.3561 - val_loss: 0.3426 - val_mse: 0.3426 - val_mae: 0.4500\n",
      "Epoch 157/495\n",
      "91/91 [==============================] - 0s 313us/sample - loss: 0.2284 - mse: 0.2284 - mae: 0.4002 - val_loss: 0.3733 - val_mse: 0.3733 - val_mae: 0.4914\n",
      "Epoch 158/495\n",
      "91/91 [==============================] - 0s 438us/sample - loss: 0.2429 - mse: 0.2429 - mae: 0.3655 - val_loss: 0.4200 - val_mse: 0.4200 - val_mae: 0.4999\n",
      "Epoch 159/495\n",
      "91/91 [==============================] - 0s 304us/sample - loss: 0.2785 - mse: 0.2785 - mae: 0.4407 - val_loss: 0.4392 - val_mse: 0.4392 - val_mae: 0.5431\n",
      "Epoch 160/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.3280 - mse: 0.3280 - mae: 0.4364 - val_loss: 0.5450 - val_mse: 0.5450 - val_mae: 0.5809\n",
      "Epoch 161/495\n",
      "91/91 [==============================] - 0s 295us/sample - loss: 0.3680 - mse: 0.3680 - mae: 0.5050 - val_loss: 0.4494 - val_mse: 0.4494 - val_mae: 0.5533\n",
      "Epoch 162/495\n",
      "91/91 [==============================] - 0s 292us/sample - loss: 0.3603 - mse: 0.3603 - mae: 0.4703 - val_loss: 0.4911 - val_mse: 0.4911 - val_mae: 0.5430\n",
      "Epoch 163/495\n",
      "91/91 [==============================] - 0s 332us/sample - loss: 0.3133 - mse: 0.3133 - mae: 0.4651 - val_loss: 0.3489 - val_mse: 0.3489 - val_mae: 0.4689\n",
      "Epoch 164/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.2651 - mse: 0.2651 - mae: 0.3954 - val_loss: 0.3969 - val_mse: 0.3969 - val_mae: 0.4704\n",
      "Epoch 165/495\n",
      "91/91 [==============================] - 0s 276us/sample - loss: 0.2321 - mse: 0.2321 - mae: 0.3940 - val_loss: 0.3002 - val_mse: 0.3002 - val_mae: 0.4198\n",
      "Epoch 166/495\n",
      "91/91 [==============================] - 0s 292us/sample - loss: 0.2130 - mse: 0.2130 - mae: 0.3458 - val_loss: 0.3635 - val_mse: 0.3635 - val_mae: 0.4424\n",
      "Epoch 167/495\n",
      "91/91 [==============================] - 0s 329us/sample - loss: 0.2038 - mse: 0.2038 - mae: 0.3640 - val_loss: 0.2866 - val_mse: 0.2866 - val_mae: 0.4029\n",
      "Epoch 168/495\n",
      "91/91 [==============================] - 0s 317us/sample - loss: 0.2012 - mse: 0.2012 - mae: 0.3360 - val_loss: 0.3682 - val_mse: 0.3682 - val_mae: 0.4491\n",
      "Epoch 169/495\n",
      "91/91 [==============================] - 0s 331us/sample - loss: 0.2057 - mse: 0.2057 - mae: 0.3641 - val_loss: 0.2892 - val_mse: 0.2892 - val_mae: 0.4081\n",
      "Epoch 170/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.2180 - mse: 0.2180 - mae: 0.3561 - val_loss: 0.4196 - val_mse: 0.4196 - val_mae: 0.5019\n",
      "Epoch 171/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.2462 - mse: 0.2462 - mae: 0.4063 - val_loss: 0.3287 - val_mse: 0.3287 - val_mae: 0.4512\n",
      "Epoch 172/495\n",
      "91/91 [==============================] - 0s 291us/sample - loss: 0.2889 - mse: 0.2889 - mae: 0.4373 - val_loss: 0.5312 - val_mse: 0.5312 - val_mae: 0.5840\n",
      "Epoch 173/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.3424 - mse: 0.3424 - mae: 0.4768 - val_loss: 0.3854 - val_mse: 0.3854 - val_mae: 0.5115\n",
      "Epoch 174/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.3550 - mse: 0.3550 - mae: 0.4938 - val_loss: 0.5102 - val_mse: 0.5102 - val_mae: 0.5593\n",
      "Epoch 175/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.3240 - mse: 0.3240 - mae: 0.4568 - val_loss: 0.3440 - val_mse: 0.3440 - val_mae: 0.4755\n",
      "Epoch 176/495\n",
      "91/91 [==============================] - 0s 305us/sample - loss: 0.2780 - mse: 0.2780 - mae: 0.4386 - val_loss: 0.4043 - val_mse: 0.4043 - val_mae: 0.4990\n",
      "Epoch 177/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.2386 - mse: 0.2386 - mae: 0.3837 - val_loss: 0.3166 - val_mse: 0.3166 - val_mae: 0.4342\n",
      "Epoch 178/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.2204 - mse: 0.2204 - mae: 0.3936 - val_loss: 0.3607 - val_mse: 0.3607 - val_mae: 0.4765\n",
      "Epoch 179/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.2122 - mse: 0.2122 - mae: 0.3499 - val_loss: 0.3413 - val_mse: 0.3413 - val_mae: 0.4481\n",
      "Epoch 180/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.2218 - mse: 0.2218 - mae: 0.3952 - val_loss: 0.3793 - val_mse: 0.3793 - val_mae: 0.4964\n",
      "Epoch 181/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.2460 - mse: 0.2460 - mae: 0.3706 - val_loss: 0.4492 - val_mse: 0.4492 - val_mae: 0.5210\n",
      "Epoch 182/495\n",
      "91/91 [==============================] - 0s 351us/sample - loss: 0.2955 - mse: 0.2955 - mae: 0.4548 - val_loss: 0.4605 - val_mse: 0.4605 - val_mae: 0.5573\n",
      "Epoch 183/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.3467 - mse: 0.3467 - mae: 0.4526 - val_loss: 0.5390 - val_mse: 0.5390 - val_mae: 0.5761\n",
      "Epoch 184/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.3564 - mse: 0.3564 - mae: 0.4987 - val_loss: 0.4141 - val_mse: 0.4141 - val_mae: 0.5263\n",
      "Epoch 185/495\n",
      "91/91 [==============================] - 0s 286us/sample - loss: 0.3157 - mse: 0.3157 - mae: 0.4343 - val_loss: 0.4341 - val_mse: 0.4341 - val_mae: 0.4978\n",
      "Epoch 186/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.2627 - mse: 0.2627 - mae: 0.4251 - val_loss: 0.3245 - val_mse: 0.3245 - val_mae: 0.4445\n",
      "Epoch 187/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.2252 - mse: 0.2252 - mae: 0.3567 - val_loss: 0.3635 - val_mse: 0.3635 - val_mae: 0.4439\n",
      "Epoch 188/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.2033 - mse: 0.2033 - mae: 0.3680 - val_loss: 0.2940 - val_mse: 0.2940 - val_mae: 0.4146\n",
      "Epoch 189/495\n",
      "91/91 [==============================] - 0s 287us/sample - loss: 0.1920 - mse: 0.1920 - mae: 0.3252 - val_loss: 0.3455 - val_mse: 0.3455 - val_mae: 0.4284\n",
      "Epoch 190/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.1874 - mse: 0.1874 - mae: 0.3498 - val_loss: 0.2864 - val_mse: 0.2864 - val_mae: 0.4043\n",
      "Epoch 191/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.1877 - mse: 0.1877 - mae: 0.3228 - val_loss: 0.3554 - val_mse: 0.3554 - val_mae: 0.4364\n",
      "Epoch 192/495\n",
      "91/91 [==============================] - 0s 263us/sample - loss: 0.1926 - mse: 0.1926 - mae: 0.3554 - val_loss: 0.2898 - val_mse: 0.2898 - val_mae: 0.4081\n",
      "Epoch 193/495\n",
      "91/91 [==============================] - 0s 460us/sample - loss: 0.2033 - mse: 0.2033 - mae: 0.3382 - val_loss: 0.3952 - val_mse: 0.3952 - val_mae: 0.4715\n",
      "Epoch 194/495\n",
      "91/91 [==============================] - 0s 335us/sample - loss: 0.2222 - mse: 0.2222 - mae: 0.3870 - val_loss: 0.3106 - val_mse: 0.3106 - val_mae: 0.4314\n",
      "Epoch 195/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.2489 - mse: 0.2489 - mae: 0.3874 - val_loss: 0.4699 - val_mse: 0.4699 - val_mae: 0.5345\n",
      "Epoch 196/495\n",
      "91/91 [==============================] - 0s 295us/sample - loss: 0.2849 - mse: 0.2849 - mae: 0.4428 - val_loss: 0.3449 - val_mse: 0.3449 - val_mae: 0.4593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/495\n",
      "91/91 [==============================] - 0s 275us/sample - loss: 0.3086 - mse: 0.3086 - mae: 0.4511 - val_loss: 0.5200 - val_mse: 0.5200 - val_mae: 0.5746\n",
      "Epoch 198/495\n",
      "91/91 [==============================] - 0s 284us/sample - loss: 0.3264 - mse: 0.3264 - mae: 0.4671 - val_loss: 0.3598 - val_mse: 0.3598 - val_mae: 0.4916\n",
      "Epoch 199/495\n",
      "91/91 [==============================] - 0s 311us/sample - loss: 0.3135 - mse: 0.3135 - mae: 0.4625 - val_loss: 0.4763 - val_mse: 0.4763 - val_mae: 0.5412\n",
      "Epoch 200/495\n",
      "91/91 [==============================] - 0s 317us/sample - loss: 0.2923 - mse: 0.2923 - mae: 0.4338 - val_loss: 0.3492 - val_mse: 0.3492 - val_mae: 0.4760\n",
      "Epoch 201/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.2673 - mse: 0.2673 - mae: 0.4311 - val_loss: 0.4034 - val_mse: 0.4034 - val_mae: 0.5091\n",
      "Epoch 202/495\n",
      "91/91 [==============================] - 0s 299us/sample - loss: 0.2396 - mse: 0.2396 - mae: 0.3847 - val_loss: 0.3405 - val_mse: 0.3405 - val_mae: 0.4518\n",
      "Epoch 203/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.2288 - mse: 0.2288 - mae: 0.4037 - val_loss: 0.3676 - val_mse: 0.3676 - val_mae: 0.4897\n",
      "Epoch 204/495\n",
      "91/91 [==============================] - 0s 252us/sample - loss: 0.2216 - mse: 0.2216 - mae: 0.3554 - val_loss: 0.3672 - val_mse: 0.3672 - val_mae: 0.4619\n",
      "Epoch 205/495\n",
      "91/91 [==============================] - 0s 153us/sample - loss: 0.2301 - mse: 0.2301 - mae: 0.4012 - val_loss: 0.3740 - val_mse: 0.3740 - val_mae: 0.4941\n",
      "Epoch 206/495\n",
      "91/91 [==============================] - 0s 130us/sample - loss: 0.2440 - mse: 0.2440 - mae: 0.3700 - val_loss: 0.4275 - val_mse: 0.4275 - val_mae: 0.4983\n",
      "Epoch 207/495\n",
      "91/91 [==============================] - 0s 121us/sample - loss: 0.2646 - mse: 0.2646 - mae: 0.4284 - val_loss: 0.3918 - val_mse: 0.3918 - val_mae: 0.5067\n",
      "Epoch 208/495\n",
      "91/91 [==============================] - 0s 164us/sample - loss: 0.2774 - mse: 0.2774 - mae: 0.3989 - val_loss: 0.4491 - val_mse: 0.4491 - val_mae: 0.5074\n",
      "Epoch 209/495\n",
      "91/91 [==============================] - 0s 142us/sample - loss: 0.2731 - mse: 0.2731 - mae: 0.4362 - val_loss: 0.3606 - val_mse: 0.3606 - val_mae: 0.4796\n",
      "Epoch 210/495\n",
      "91/91 [==============================] - 0s 142us/sample - loss: 0.2558 - mse: 0.2558 - mae: 0.3834 - val_loss: 0.4047 - val_mse: 0.4047 - val_mae: 0.4740\n",
      "Epoch 211/495\n",
      "91/91 [==============================] - 0s 132us/sample - loss: 0.2334 - mse: 0.2334 - mae: 0.4004 - val_loss: 0.3188 - val_mse: 0.3188 - val_mae: 0.4402\n",
      "Epoch 212/495\n",
      "91/91 [==============================] - 0s 164us/sample - loss: 0.2153 - mse: 0.2153 - mae: 0.3481 - val_loss: 0.3691 - val_mse: 0.3691 - val_mae: 0.4476\n",
      "Epoch 213/495\n",
      "91/91 [==============================] - 0s 149us/sample - loss: 0.2029 - mse: 0.2029 - mae: 0.3698 - val_loss: 0.2986 - val_mse: 0.2986 - val_mae: 0.4197\n",
      "Epoch 214/495\n",
      "91/91 [==============================] - 0s 155us/sample - loss: 0.1960 - mse: 0.1960 - mae: 0.3296 - val_loss: 0.3591 - val_mse: 0.3591 - val_mae: 0.4399\n",
      "Epoch 215/495\n",
      "91/91 [==============================] - 0s 142us/sample - loss: 0.1935 - mse: 0.1935 - mae: 0.3599 - val_loss: 0.2928 - val_mse: 0.2928 - val_mae: 0.4132\n",
      "Epoch 216/495\n",
      "91/91 [==============================] - 0s 148us/sample - loss: 0.1949 - mse: 0.1949 - mae: 0.3290 - val_loss: 0.3693 - val_mse: 0.3693 - val_mae: 0.4488\n",
      "Epoch 217/495\n",
      "91/91 [==============================] - 0s 142us/sample - loss: 0.2000 - mse: 0.2000 - mae: 0.3670 - val_loss: 0.2960 - val_mse: 0.2960 - val_mae: 0.4157\n",
      "Epoch 218/495\n",
      "91/91 [==============================] - 0s 132us/sample - loss: 0.2083 - mse: 0.2083 - mae: 0.3440 - val_loss: 0.3959 - val_mse: 0.3959 - val_mae: 0.4727\n",
      "Epoch 219/495\n",
      "91/91 [==============================] - 0s 139us/sample - loss: 0.2205 - mse: 0.2205 - mae: 0.3876 - val_loss: 0.3059 - val_mse: 0.3059 - val_mae: 0.4288\n",
      "Epoch 220/495\n",
      "91/91 [==============================] - 0s 154us/sample - loss: 0.2337 - mse: 0.2337 - mae: 0.3725 - val_loss: 0.4343 - val_mse: 0.4343 - val_mae: 0.5073\n",
      "Epoch 221/495\n",
      "91/91 [==============================] - 0s 140us/sample - loss: 0.2510 - mse: 0.2510 - mae: 0.4160 - val_loss: 0.3191 - val_mse: 0.3191 - val_mae: 0.4396\n",
      "Epoch 222/495\n",
      "91/91 [==============================] - 0s 136us/sample - loss: 0.2651 - mse: 0.2651 - mae: 0.4111 - val_loss: 0.4846 - val_mse: 0.4846 - val_mae: 0.5504\n",
      "Epoch 223/495\n",
      "91/91 [==============================] - 0s 142us/sample - loss: 0.2913 - mse: 0.2913 - mae: 0.4411 - val_loss: 0.3590 - val_mse: 0.3590 - val_mae: 0.4924\n",
      "Epoch 224/495\n",
      "91/91 [==============================] - 0s 148us/sample - loss: 0.3060 - mse: 0.3060 - mae: 0.4571 - val_loss: 0.4899 - val_mse: 0.4899 - val_mae: 0.5518\n",
      "Epoch 225/495\n",
      "91/91 [==============================] - 0s 283us/sample - loss: 0.3012 - mse: 0.3012 - mae: 0.4418 - val_loss: 0.3554 - val_mse: 0.3554 - val_mae: 0.4805\n",
      "Epoch 226/495\n",
      "91/91 [==============================] - 0s 321us/sample - loss: 0.2712 - mse: 0.2712 - mae: 0.4349 - val_loss: 0.3981 - val_mse: 0.3981 - val_mae: 0.5049\n",
      "Epoch 227/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.2304 - mse: 0.2304 - mae: 0.3781 - val_loss: 0.3250 - val_mse: 0.3250 - val_mae: 0.4370\n",
      "Epoch 228/495\n",
      "91/91 [==============================] - 0s 317us/sample - loss: 0.2097 - mse: 0.2097 - mae: 0.3858 - val_loss: 0.3449 - val_mse: 0.3449 - val_mae: 0.4697\n",
      "Epoch 229/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.1965 - mse: 0.1965 - mae: 0.3341 - val_loss: 0.3357 - val_mse: 0.3357 - val_mae: 0.4362\n",
      "Epoch 230/495\n",
      "91/91 [==============================] - 0s 286us/sample - loss: 0.1985 - mse: 0.1985 - mae: 0.3715 - val_loss: 0.3421 - val_mse: 0.3421 - val_mae: 0.4693\n",
      "Epoch 231/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.2082 - mse: 0.2082 - mae: 0.3377 - val_loss: 0.3902 - val_mse: 0.3902 - val_mae: 0.4672\n",
      "Epoch 232/495\n",
      "91/91 [==============================] - 0s 303us/sample - loss: 0.2294 - mse: 0.2294 - mae: 0.3976 - val_loss: 0.3730 - val_mse: 0.3730 - val_mae: 0.4903\n",
      "Epoch 233/495\n",
      "91/91 [==============================] - 0s 299us/sample - loss: 0.2538 - mse: 0.2538 - mae: 0.3786 - val_loss: 0.4479 - val_mse: 0.4479 - val_mae: 0.5047\n",
      "Epoch 234/495\n",
      "91/91 [==============================] - 0s 351us/sample - loss: 0.2674 - mse: 0.2674 - mae: 0.4324 - val_loss: 0.3690 - val_mse: 0.3690 - val_mae: 0.4877\n",
      "Epoch 235/495\n",
      "91/91 [==============================] - 0s 313us/sample - loss: 0.2614 - mse: 0.2614 - mae: 0.3886 - val_loss: 0.4176 - val_mse: 0.4176 - val_mae: 0.4814\n",
      "Epoch 236/495\n",
      "91/91 [==============================] - 0s 319us/sample - loss: 0.2392 - mse: 0.2392 - mae: 0.4073 - val_loss: 0.3226 - val_mse: 0.3226 - val_mae: 0.4443\n",
      "Epoch 237/495\n",
      "91/91 [==============================] - 0s 289us/sample - loss: 0.2166 - mse: 0.2166 - mae: 0.3497 - val_loss: 0.3691 - val_mse: 0.3691 - val_mae: 0.4471\n",
      "Epoch 238/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.1990 - mse: 0.1990 - mae: 0.3678 - val_loss: 0.2952 - val_mse: 0.2952 - val_mae: 0.4183\n",
      "Epoch 239/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.1882 - mse: 0.1882 - mae: 0.3218 - val_loss: 0.3494 - val_mse: 0.3494 - val_mae: 0.4325\n",
      "Epoch 240/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.1825 - mse: 0.1825 - mae: 0.3502 - val_loss: 0.2857 - val_mse: 0.2857 - val_mae: 0.4085\n",
      "Epoch 241/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.1812 - mse: 0.1812 - mae: 0.3154 - val_loss: 0.3522 - val_mse: 0.3522 - val_mae: 0.4349\n",
      "Epoch 242/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.1834 - mse: 0.1834 - mae: 0.3507 - val_loss: 0.2852 - val_mse: 0.2852 - val_mae: 0.4067\n",
      "Epoch 243/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.1893 - mse: 0.1893 - mae: 0.3244 - val_loss: 0.3738 - val_mse: 0.3738 - val_mae: 0.4563\n",
      "Epoch 244/495\n",
      "91/91 [==============================] - 0s 294us/sample - loss: 0.1994 - mse: 0.1994 - mae: 0.3683 - val_loss: 0.2936 - val_mse: 0.2936 - val_mae: 0.4180\n",
      "Epoch 245/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.2132 - mse: 0.2132 - mae: 0.3526 - val_loss: 0.4166 - val_mse: 0.4166 - val_mae: 0.4956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.2337 - mse: 0.2337 - mae: 0.4024 - val_loss: 0.3142 - val_mse: 0.3142 - val_mae: 0.4386\n",
      "Epoch 247/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.2546 - mse: 0.2546 - mae: 0.4016 - val_loss: 0.4814 - val_mse: 0.4814 - val_mae: 0.5488\n",
      "Epoch 248/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.2858 - mse: 0.2858 - mae: 0.4376 - val_loss: 0.3541 - val_mse: 0.3541 - val_mae: 0.4895\n",
      "Epoch 249/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.2983 - mse: 0.2983 - mae: 0.4510 - val_loss: 0.4789 - val_mse: 0.4789 - val_mae: 0.5433\n",
      "Epoch 250/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.2886 - mse: 0.2886 - mae: 0.4337 - val_loss: 0.3421 - val_mse: 0.3421 - val_mae: 0.4698\n",
      "Epoch 251/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.2533 - mse: 0.2533 - mae: 0.4203 - val_loss: 0.3842 - val_mse: 0.3842 - val_mae: 0.4931\n",
      "Epoch 252/495\n",
      "91/91 [==============================] - 0s 263us/sample - loss: 0.2151 - mse: 0.2151 - mae: 0.3665 - val_loss: 0.3130 - val_mse: 0.3130 - val_mae: 0.4264\n",
      "Epoch 253/495\n",
      "91/91 [==============================] - 0s 308us/sample - loss: 0.1954 - mse: 0.1954 - mae: 0.3708 - val_loss: 0.3357 - val_mse: 0.3357 - val_mae: 0.4605\n",
      "Epoch 254/495\n",
      "91/91 [==============================] - 0s 317us/sample - loss: 0.1838 - mse: 0.1838 - mae: 0.3249 - val_loss: 0.3233 - val_mse: 0.3233 - val_mae: 0.4245\n",
      "Epoch 255/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.1854 - mse: 0.1854 - mae: 0.3586 - val_loss: 0.3329 - val_mse: 0.3329 - val_mae: 0.4627\n",
      "Epoch 256/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.1944 - mse: 0.1944 - mae: 0.3266 - val_loss: 0.3756 - val_mse: 0.3756 - val_mae: 0.4551\n",
      "Epoch 257/495\n",
      "91/91 [==============================] - 0s 295us/sample - loss: 0.2150 - mse: 0.2150 - mae: 0.3847 - val_loss: 0.3645 - val_mse: 0.3645 - val_mae: 0.4837\n",
      "Epoch 258/495\n",
      "91/91 [==============================] - 0s 308us/sample - loss: 0.2405 - mse: 0.2405 - mae: 0.3687 - val_loss: 0.4395 - val_mse: 0.4395 - val_mae: 0.4974\n",
      "Epoch 259/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.2572 - mse: 0.2572 - mae: 0.4243 - val_loss: 0.3653 - val_mse: 0.3653 - val_mae: 0.4837\n",
      "Epoch 260/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.2536 - mse: 0.2536 - mae: 0.3834 - val_loss: 0.4126 - val_mse: 0.4126 - val_mae: 0.4759\n",
      "Epoch 261/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.2314 - mse: 0.2314 - mae: 0.4016 - val_loss: 0.3181 - val_mse: 0.3181 - val_mae: 0.4417\n",
      "Epoch 262/495\n",
      "91/91 [==============================] - 0s 289us/sample - loss: 0.2082 - mse: 0.2082 - mae: 0.3414 - val_loss: 0.3622 - val_mse: 0.3622 - val_mae: 0.4406\n",
      "Epoch 263/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.1899 - mse: 0.1899 - mae: 0.3598 - val_loss: 0.2897 - val_mse: 0.2897 - val_mae: 0.4145\n",
      "Epoch 264/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.1790 - mse: 0.1790 - mae: 0.3129 - val_loss: 0.3425 - val_mse: 0.3425 - val_mae: 0.4263\n",
      "Epoch 265/495\n",
      "91/91 [==============================] - 0s 292us/sample - loss: 0.1732 - mse: 0.1732 - mae: 0.3416 - val_loss: 0.2793 - val_mse: 0.2793 - val_mae: 0.4048\n",
      "Epoch 266/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.1718 - mse: 0.1718 - mae: 0.3066 - val_loss: 0.3459 - val_mse: 0.3459 - val_mae: 0.4304\n",
      "Epoch 267/495\n",
      "91/91 [==============================] - 0s 276us/sample - loss: 0.1739 - mse: 0.1739 - mae: 0.3419 - val_loss: 0.2778 - val_mse: 0.2778 - val_mae: 0.4033\n",
      "Epoch 268/495\n",
      "91/91 [==============================] - 0s 317us/sample - loss: 0.1799 - mse: 0.1799 - mae: 0.3156 - val_loss: 0.3685 - val_mse: 0.3685 - val_mae: 0.4550\n",
      "Epoch 269/495\n",
      "91/91 [==============================] - 0s 295us/sample - loss: 0.1904 - mse: 0.1904 - mae: 0.3610 - val_loss: 0.2869 - val_mse: 0.2869 - val_mae: 0.4166\n",
      "Epoch 270/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.2059 - mse: 0.2059 - mae: 0.3474 - val_loss: 0.4171 - val_mse: 0.4171 - val_mae: 0.4997\n",
      "Epoch 271/495\n",
      "91/91 [==============================] - 0s 267us/sample - loss: 0.2303 - mse: 0.2303 - mae: 0.4010 - val_loss: 0.3165 - val_mse: 0.3165 - val_mae: 0.4449\n",
      "Epoch 272/495\n",
      "91/91 [==============================] - 0s 284us/sample - loss: 0.2548 - mse: 0.2548 - mae: 0.4053 - val_loss: 0.4783 - val_mse: 0.4783 - val_mae: 0.5467\n",
      "Epoch 273/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.2821 - mse: 0.2821 - mae: 0.4341 - val_loss: 0.3450 - val_mse: 0.3450 - val_mae: 0.4813\n",
      "Epoch 274/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.2769 - mse: 0.2769 - mae: 0.4343 - val_loss: 0.4387 - val_mse: 0.4387 - val_mae: 0.5209\n",
      "Epoch 275/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.2521 - mse: 0.2521 - mae: 0.4060 - val_loss: 0.3199 - val_mse: 0.3199 - val_mae: 0.4470\n",
      "Epoch 276/495\n",
      "91/91 [==============================] - 0s 340us/sample - loss: 0.2196 - mse: 0.2196 - mae: 0.3920 - val_loss: 0.3593 - val_mse: 0.3593 - val_mae: 0.4751\n",
      "Epoch 277/495\n",
      "91/91 [==============================] - 0s 291us/sample - loss: 0.1926 - mse: 0.1926 - mae: 0.3445 - val_loss: 0.3040 - val_mse: 0.3040 - val_mae: 0.4146\n",
      "Epoch 278/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.1803 - mse: 0.1803 - mae: 0.3548 - val_loss: 0.3272 - val_mse: 0.3272 - val_mae: 0.4547\n",
      "Epoch 279/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.1747 - mse: 0.1747 - mae: 0.3161 - val_loss: 0.3227 - val_mse: 0.3227 - val_mae: 0.4215\n",
      "Epoch 280/495\n",
      "91/91 [==============================] - 0s 316us/sample - loss: 0.1803 - mse: 0.1803 - mae: 0.3522 - val_loss: 0.3329 - val_mse: 0.3329 - val_mae: 0.4632\n",
      "Epoch 281/495\n",
      "91/91 [==============================] - 0s 315us/sample - loss: 0.1936 - mse: 0.1936 - mae: 0.3271 - val_loss: 0.3848 - val_mse: 0.3848 - val_mae: 0.4604\n",
      "Epoch 282/495\n",
      "91/91 [==============================] - 0s 302us/sample - loss: 0.2179 - mse: 0.2179 - mae: 0.3872 - val_loss: 0.3666 - val_mse: 0.3666 - val_mae: 0.4842\n",
      "Epoch 283/495\n",
      "91/91 [==============================] - 0s 272us/sample - loss: 0.2430 - mse: 0.2430 - mae: 0.3735 - val_loss: 0.4372 - val_mse: 0.4372 - val_mae: 0.4936\n",
      "Epoch 284/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.2504 - mse: 0.2504 - mae: 0.4190 - val_loss: 0.3492 - val_mse: 0.3492 - val_mae: 0.4692\n",
      "Epoch 285/495\n",
      "91/91 [==============================] - 0s 297us/sample - loss: 0.2365 - mse: 0.2365 - mae: 0.3702 - val_loss: 0.3919 - val_mse: 0.3919 - val_mae: 0.4585\n",
      "Epoch 286/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.2102 - mse: 0.2102 - mae: 0.3818 - val_loss: 0.3017 - val_mse: 0.3017 - val_mae: 0.4286\n",
      "Epoch 287/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.1890 - mse: 0.1890 - mae: 0.3242 - val_loss: 0.3483 - val_mse: 0.3483 - val_mae: 0.4284\n",
      "Epoch 288/495\n",
      "91/91 [==============================] - 0s 301us/sample - loss: 0.1744 - mse: 0.1744 - mae: 0.3446 - val_loss: 0.2790 - val_mse: 0.2790 - val_mae: 0.4062\n",
      "Epoch 289/495\n",
      "91/91 [==============================] - 0s 295us/sample - loss: 0.1667 - mse: 0.1667 - mae: 0.3022 - val_loss: 0.3364 - val_mse: 0.3364 - val_mae: 0.4220\n",
      "Epoch 290/495\n",
      "91/91 [==============================] - 0s 304us/sample - loss: 0.1635 - mse: 0.1635 - mae: 0.3319 - val_loss: 0.2712 - val_mse: 0.2712 - val_mae: 0.4001\n",
      "Epoch 291/495\n",
      "91/91 [==============================] - 0s 340us/sample - loss: 0.1644 - mse: 0.1644 - mae: 0.3006 - val_loss: 0.3459 - val_mse: 0.3459 - val_mae: 0.4354\n",
      "Epoch 292/495\n",
      "91/91 [==============================] - 0s 313us/sample - loss: 0.1689 - mse: 0.1689 - mae: 0.3384 - val_loss: 0.2721 - val_mse: 0.2721 - val_mae: 0.4022\n",
      "Epoch 293/495\n",
      "91/91 [==============================] - 0s 328us/sample - loss: 0.1779 - mse: 0.1779 - mae: 0.3176 - val_loss: 0.3776 - val_mse: 0.3776 - val_mae: 0.4693\n",
      "Epoch 294/495\n",
      "91/91 [==============================] - 0s 317us/sample - loss: 0.1938 - mse: 0.1938 - mae: 0.3654 - val_loss: 0.2915 - val_mse: 0.2915 - val_mae: 0.4235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/495\n",
      "91/91 [==============================] - 0s 298us/sample - loss: 0.2162 - mse: 0.2162 - mae: 0.3654 - val_loss: 0.4399 - val_mse: 0.4399 - val_mae: 0.5231\n",
      "Epoch 296/495\n",
      "91/91 [==============================] - 0s 351us/sample - loss: 0.2479 - mse: 0.2479 - mae: 0.4105 - val_loss: 0.3293 - val_mse: 0.3293 - val_mae: 0.4707\n",
      "Epoch 297/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.2621 - mse: 0.2621 - mae: 0.4189 - val_loss: 0.4520 - val_mse: 0.4520 - val_mae: 0.5298\n",
      "Epoch 298/495\n",
      "91/91 [==============================] - 0s 312us/sample - loss: 0.2597 - mse: 0.2597 - mae: 0.4114 - val_loss: 0.3209 - val_mse: 0.3209 - val_mae: 0.4549\n",
      "Epoch 299/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.2309 - mse: 0.2309 - mae: 0.3999 - val_loss: 0.3794 - val_mse: 0.3794 - val_mae: 0.4860\n",
      "Epoch 300/495\n",
      "91/91 [==============================] - 0s 351us/sample - loss: 0.2019 - mse: 0.2019 - mae: 0.3600 - val_loss: 0.2979 - val_mse: 0.2979 - val_mae: 0.4161\n",
      "Epoch 301/495\n",
      "91/91 [==============================] - 0s 287us/sample - loss: 0.1825 - mse: 0.1825 - mae: 0.3557 - val_loss: 0.3321 - val_mse: 0.3321 - val_mae: 0.4556\n",
      "Epoch 302/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.1703 - mse: 0.1703 - mae: 0.3198 - val_loss: 0.3018 - val_mse: 0.3018 - val_mae: 0.4068\n",
      "Epoch 303/495\n",
      "91/91 [==============================] - 0s 297us/sample - loss: 0.1686 - mse: 0.1686 - mae: 0.3401 - val_loss: 0.3220 - val_mse: 0.3220 - val_mae: 0.4524\n",
      "Epoch 304/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.1728 - mse: 0.1728 - mae: 0.3108 - val_loss: 0.3427 - val_mse: 0.3427 - val_mae: 0.4321\n",
      "Epoch 305/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.1887 - mse: 0.1887 - mae: 0.3599 - val_loss: 0.3474 - val_mse: 0.3474 - val_mae: 0.4724\n",
      "Epoch 306/495\n",
      "91/91 [==============================] - 0s 263us/sample - loss: 0.2136 - mse: 0.2136 - mae: 0.3494 - val_loss: 0.4219 - val_mse: 0.4219 - val_mae: 0.4829\n",
      "Epoch 307/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.2397 - mse: 0.2397 - mae: 0.4076 - val_loss: 0.3646 - val_mse: 0.3646 - val_mae: 0.4818\n",
      "Epoch 308/495\n",
      "91/91 [==============================] - 0s 312us/sample - loss: 0.2469 - mse: 0.2469 - mae: 0.3812 - val_loss: 0.4153 - val_mse: 0.4153 - val_mae: 0.4759\n",
      "Epoch 309/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.2262 - mse: 0.2262 - mae: 0.3985 - val_loss: 0.3137 - val_mse: 0.3137 - val_mae: 0.4399\n",
      "Epoch 310/495\n",
      "91/91 [==============================] - 0s 309us/sample - loss: 0.1999 - mse: 0.1999 - mae: 0.3359 - val_loss: 0.3565 - val_mse: 0.3565 - val_mae: 0.4325\n",
      "Epoch 311/495\n",
      "91/91 [==============================] - 0s 281us/sample - loss: 0.1775 - mse: 0.1775 - mae: 0.3490 - val_loss: 0.2796 - val_mse: 0.2796 - val_mae: 0.4080\n",
      "Epoch 312/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.1645 - mse: 0.1645 - mae: 0.3003 - val_loss: 0.3325 - val_mse: 0.3325 - val_mae: 0.4182\n",
      "Epoch 313/495\n",
      "91/91 [==============================] - 0s 328us/sample - loss: 0.1575 - mse: 0.1575 - mae: 0.3263 - val_loss: 0.2672 - val_mse: 0.2672 - val_mae: 0.3988\n",
      "Epoch 314/495\n",
      "91/91 [==============================] - 0s 315us/sample - loss: 0.1555 - mse: 0.1555 - mae: 0.2926 - val_loss: 0.3347 - val_mse: 0.3347 - val_mae: 0.4273\n",
      "Epoch 315/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.1571 - mse: 0.1571 - mae: 0.3268 - val_loss: 0.2644 - val_mse: 0.2644 - val_mae: 0.3973\n",
      "Epoch 316/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.1628 - mse: 0.1628 - mae: 0.3030 - val_loss: 0.3575 - val_mse: 0.3575 - val_mae: 0.4544\n",
      "Epoch 317/495\n",
      "91/91 [==============================] - 0s 325us/sample - loss: 0.1739 - mse: 0.1739 - mae: 0.3458 - val_loss: 0.2767 - val_mse: 0.2767 - val_mae: 0.4126\n",
      "Epoch 318/495\n",
      "91/91 [==============================] - 0s 295us/sample - loss: 0.1920 - mse: 0.1920 - mae: 0.3407 - val_loss: 0.4112 - val_mse: 0.4112 - val_mae: 0.5031\n",
      "Epoch 319/495\n",
      "91/91 [==============================] - 0s 277us/sample - loss: 0.2210 - mse: 0.2210 - mae: 0.3904 - val_loss: 0.3149 - val_mse: 0.3149 - val_mae: 0.4559\n",
      "Epoch 320/495\n",
      "91/91 [==============================] - 0s 305us/sample - loss: 0.2428 - mse: 0.2428 - mae: 0.3996 - val_loss: 0.4436 - val_mse: 0.4436 - val_mae: 0.5274\n",
      "Epoch 321/495\n",
      "91/91 [==============================] - 0s 287us/sample - loss: 0.2515 - mse: 0.2515 - mae: 0.4069 - val_loss: 0.3164 - val_mse: 0.3164 - val_mae: 0.4558\n",
      "Epoch 322/495\n",
      "91/91 [==============================] - 0s 329us/sample - loss: 0.2281 - mse: 0.2281 - mae: 0.3944 - val_loss: 0.3843 - val_mse: 0.3843 - val_mae: 0.4865\n",
      "Epoch 323/495\n",
      "91/91 [==============================] - 0s 317us/sample - loss: 0.2023 - mse: 0.2023 - mae: 0.3635 - val_loss: 0.2925 - val_mse: 0.2925 - val_mae: 0.4167\n",
      "Epoch 324/495\n",
      "91/91 [==============================] - 0s 278us/sample - loss: 0.1807 - mse: 0.1807 - mae: 0.3531 - val_loss: 0.3347 - val_mse: 0.3347 - val_mae: 0.4570\n",
      "Epoch 325/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.1668 - mse: 0.1668 - mae: 0.3210 - val_loss: 0.2905 - val_mse: 0.2905 - val_mae: 0.3990\n",
      "Epoch 326/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.1618 - mse: 0.1618 - mae: 0.3327 - val_loss: 0.3180 - val_mse: 0.3180 - val_mae: 0.4471\n",
      "Epoch 327/495\n",
      "91/91 [==============================] - 0s 320us/sample - loss: 0.1620 - mse: 0.1620 - mae: 0.3054 - val_loss: 0.3184 - val_mse: 0.3184 - val_mae: 0.4147\n",
      "Epoch 328/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.1721 - mse: 0.1721 - mae: 0.3425 - val_loss: 0.3327 - val_mse: 0.3327 - val_mae: 0.4639\n",
      "Epoch 329/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.1912 - mse: 0.1912 - mae: 0.3285 - val_loss: 0.3957 - val_mse: 0.3957 - val_mae: 0.4660\n",
      "Epoch 330/495\n",
      "91/91 [==============================] - 0s 295us/sample - loss: 0.2206 - mse: 0.2206 - mae: 0.3882 - val_loss: 0.3655 - val_mse: 0.3655 - val_mae: 0.4843\n",
      "Epoch 331/495\n",
      "91/91 [==============================] - 0s 328us/sample - loss: 0.2424 - mse: 0.2424 - mae: 0.3779 - val_loss: 0.4270 - val_mse: 0.4270 - val_mae: 0.4845\n",
      "Epoch 332/495\n",
      "91/91 [==============================] - 0s 372us/sample - loss: 0.2339 - mse: 0.2339 - mae: 0.4053 - val_loss: 0.3230 - val_mse: 0.3230 - val_mae: 0.4477\n",
      "Epoch 333/495\n",
      "91/91 [==============================] - 0s 341us/sample - loss: 0.2084 - mse: 0.2084 - mae: 0.3475 - val_loss: 0.3643 - val_mse: 0.3643 - val_mae: 0.4368\n",
      "Epoch 334/495\n",
      "91/91 [==============================] - 0s 308us/sample - loss: 0.1804 - mse: 0.1804 - mae: 0.3531 - val_loss: 0.2796 - val_mse: 0.2796 - val_mae: 0.4093\n",
      "Epoch 335/495\n",
      "91/91 [==============================] - 0s 317us/sample - loss: 0.1629 - mse: 0.1629 - mae: 0.2995 - val_loss: 0.3304 - val_mse: 0.3304 - val_mae: 0.4173\n",
      "Epoch 336/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.1529 - mse: 0.1529 - mae: 0.3220 - val_loss: 0.2637 - val_mse: 0.2637 - val_mae: 0.3973\n",
      "Epoch 337/495\n",
      "91/91 [==============================] - 0s 456us/sample - loss: 0.1490 - mse: 0.1490 - mae: 0.2868 - val_loss: 0.3276 - val_mse: 0.3276 - val_mae: 0.4234\n",
      "Epoch 338/495\n",
      "91/91 [==============================] - 0s 329us/sample - loss: 0.1490 - mse: 0.1490 - mae: 0.3186 - val_loss: 0.2591 - val_mse: 0.2591 - val_mae: 0.3938\n",
      "Epoch 339/495\n",
      "91/91 [==============================] - 0s 295us/sample - loss: 0.1530 - mse: 0.1530 - mae: 0.2936 - val_loss: 0.3456 - val_mse: 0.3456 - val_mae: 0.4470\n",
      "Epoch 340/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.1615 - mse: 0.1615 - mae: 0.3332 - val_loss: 0.2676 - val_mse: 0.2676 - val_mae: 0.4046\n",
      "Epoch 341/495\n",
      "91/91 [==============================] - 0s 372us/sample - loss: 0.1766 - mse: 0.1766 - mae: 0.3251 - val_loss: 0.3918 - val_mse: 0.3918 - val_mae: 0.4909\n",
      "Epoch 342/495\n",
      "91/91 [==============================] - 0s 374us/sample - loss: 0.2020 - mse: 0.2020 - mae: 0.3743 - val_loss: 0.3034 - val_mse: 0.3034 - val_mae: 0.4438\n",
      "Epoch 343/495\n",
      "91/91 [==============================] - 0s 351us/sample - loss: 0.2258 - mse: 0.2258 - mae: 0.3832 - val_loss: 0.4308 - val_mse: 0.4308 - val_mae: 0.5205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.2393 - mse: 0.2393 - mae: 0.3983 - val_loss: 0.3100 - val_mse: 0.3100 - val_mae: 0.4524\n",
      "Epoch 345/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.2201 - mse: 0.2201 - mae: 0.3855 - val_loss: 0.3805 - val_mse: 0.3805 - val_mae: 0.4828\n",
      "Epoch 346/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.1972 - mse: 0.1972 - mae: 0.3599 - val_loss: 0.2866 - val_mse: 0.2866 - val_mae: 0.4135\n",
      "Epoch 347/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.1752 - mse: 0.1752 - mae: 0.3462 - val_loss: 0.3329 - val_mse: 0.3329 - val_mae: 0.4544\n",
      "Epoch 348/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.1614 - mse: 0.1614 - mae: 0.3188 - val_loss: 0.2819 - val_mse: 0.2819 - val_mae: 0.3933\n",
      "Epoch 349/495\n",
      "91/91 [==============================] - 0s 279us/sample - loss: 0.1551 - mse: 0.1551 - mae: 0.3241 - val_loss: 0.3149 - val_mse: 0.3149 - val_mae: 0.4426\n",
      "Epoch 350/495\n",
      "91/91 [==============================] - 0s 317us/sample - loss: 0.1537 - mse: 0.1537 - mae: 0.3019 - val_loss: 0.3019 - val_mse: 0.3019 - val_mae: 0.4016\n",
      "Epoch 351/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.1604 - mse: 0.1604 - mae: 0.3290 - val_loss: 0.3230 - val_mse: 0.3230 - val_mae: 0.4560\n",
      "Epoch 352/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.1750 - mse: 0.1750 - mae: 0.3140 - val_loss: 0.3709 - val_mse: 0.3709 - val_mae: 0.4484\n",
      "Epoch 353/495\n",
      "91/91 [==============================] - 0s 299us/sample - loss: 0.2028 - mse: 0.2028 - mae: 0.3718 - val_loss: 0.3604 - val_mse: 0.3604 - val_mae: 0.4826\n",
      "Epoch 354/495\n",
      "91/91 [==============================] - 0s 263us/sample - loss: 0.2320 - mse: 0.2320 - mae: 0.3701 - val_loss: 0.4311 - val_mse: 0.4311 - val_mae: 0.4864\n",
      "Epoch 355/495\n",
      "91/91 [==============================] - 0s 287us/sample - loss: 0.2365 - mse: 0.2365 - mae: 0.4064 - val_loss: 0.3309 - val_mse: 0.3309 - val_mae: 0.4546\n",
      "Epoch 356/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.2148 - mse: 0.2148 - mae: 0.3565 - val_loss: 0.3710 - val_mse: 0.3710 - val_mae: 0.4406\n",
      "Epoch 357/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.1828 - mse: 0.1828 - mae: 0.3561 - val_loss: 0.2790 - val_mse: 0.2790 - val_mae: 0.4094\n",
      "Epoch 358/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.1617 - mse: 0.1617 - mae: 0.2990 - val_loss: 0.3292 - val_mse: 0.3292 - val_mae: 0.4174\n",
      "Epoch 359/495\n",
      "91/91 [==============================] - 0s 290us/sample - loss: 0.1491 - mse: 0.1491 - mae: 0.3183 - val_loss: 0.2601 - val_mse: 0.2601 - val_mae: 0.3952\n",
      "Epoch 360/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.1438 - mse: 0.1438 - mae: 0.2821 - val_loss: 0.3226 - val_mse: 0.3226 - val_mae: 0.4213\n",
      "Epoch 361/495\n",
      "91/91 [==============================] - 0s 295us/sample - loss: 0.1426 - mse: 0.1426 - mae: 0.3119 - val_loss: 0.2546 - val_mse: 0.2546 - val_mae: 0.3904\n",
      "Epoch 362/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.1453 - mse: 0.1453 - mae: 0.2869 - val_loss: 0.3365 - val_mse: 0.3365 - val_mae: 0.4416\n",
      "Epoch 363/495\n",
      "91/91 [==============================] - 0s 288us/sample - loss: 0.1520 - mse: 0.1520 - mae: 0.3235 - val_loss: 0.2608 - val_mse: 0.2608 - val_mae: 0.3978\n",
      "Epoch 364/495\n",
      "91/91 [==============================] - 0s 340us/sample - loss: 0.1646 - mse: 0.1646 - mae: 0.3132 - val_loss: 0.3761 - val_mse: 0.3761 - val_mae: 0.4807\n",
      "Epoch 365/495\n",
      "91/91 [==============================] - 0s 336us/sample - loss: 0.1865 - mse: 0.1865 - mae: 0.3596 - val_loss: 0.2930 - val_mse: 0.2930 - val_mae: 0.4327\n",
      "Epoch 366/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.2100 - mse: 0.2100 - mae: 0.3679 - val_loss: 0.4177 - val_mse: 0.4177 - val_mae: 0.5130\n",
      "Epoch 367/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.2265 - mse: 0.2265 - mae: 0.3891 - val_loss: 0.3038 - val_mse: 0.3038 - val_mae: 0.4482\n",
      "Epoch 368/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.2117 - mse: 0.2117 - mae: 0.3764 - val_loss: 0.3752 - val_mse: 0.3752 - val_mae: 0.4791\n",
      "Epoch 369/495\n",
      "91/91 [==============================] - 0s 288us/sample - loss: 0.1913 - mse: 0.1913 - mae: 0.3559 - val_loss: 0.2810 - val_mse: 0.2810 - val_mae: 0.4108\n",
      "Epoch 370/495\n",
      "91/91 [==============================] - 0s 283us/sample - loss: 0.1691 - mse: 0.1691 - mae: 0.3382 - val_loss: 0.3295 - val_mse: 0.3295 - val_mae: 0.4502\n",
      "Epoch 371/495\n",
      "91/91 [==============================] - 0s 282us/sample - loss: 0.1556 - mse: 0.1556 - mae: 0.3151 - val_loss: 0.2740 - val_mse: 0.2740 - val_mae: 0.3869\n",
      "Epoch 372/495\n",
      "91/91 [==============================] - 0s 280us/sample - loss: 0.1484 - mse: 0.1484 - mae: 0.3156 - val_loss: 0.3115 - val_mse: 0.3115 - val_mae: 0.4392\n",
      "Epoch 373/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.1461 - mse: 0.1461 - mae: 0.2981 - val_loss: 0.2877 - val_mse: 0.2877 - val_mae: 0.3909\n",
      "Epoch 374/495\n",
      "91/91 [==============================] - 0s 264us/sample - loss: 0.1502 - mse: 0.1502 - mae: 0.3171 - val_loss: 0.3153 - val_mse: 0.3153 - val_mae: 0.4489\n",
      "Epoch 375/495\n",
      "91/91 [==============================] - 0s 295us/sample - loss: 0.1606 - mse: 0.1606 - mae: 0.3020 - val_loss: 0.3443 - val_mse: 0.3443 - val_mae: 0.4276\n",
      "Epoch 376/495\n",
      "91/91 [==============================] - 0s 302us/sample - loss: 0.1842 - mse: 0.1842 - mae: 0.3542 - val_loss: 0.3513 - val_mse: 0.3513 - val_mae: 0.4778\n",
      "Epoch 377/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.2162 - mse: 0.2162 - mae: 0.3580 - val_loss: 0.4291 - val_mse: 0.4291 - val_mae: 0.4831\n",
      "Epoch 378/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.2357 - mse: 0.2357 - mae: 0.4034 - val_loss: 0.3408 - val_mse: 0.3408 - val_mae: 0.4636\n",
      "Epoch 379/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.2232 - mse: 0.2232 - mae: 0.3664 - val_loss: 0.3814 - val_mse: 0.3814 - val_mae: 0.4492\n",
      "Epoch 380/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.1884 - mse: 0.1884 - mae: 0.3623 - val_loss: 0.2800 - val_mse: 0.2800 - val_mae: 0.4106\n",
      "Epoch 381/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.1627 - mse: 0.1627 - mae: 0.3017 - val_loss: 0.3292 - val_mse: 0.3292 - val_mae: 0.4179\n",
      "Epoch 382/495\n",
      "91/91 [==============================] - 0s 287us/sample - loss: 0.1465 - mse: 0.1465 - mae: 0.3159 - val_loss: 0.2571 - val_mse: 0.2571 - val_mae: 0.3933\n",
      "Epoch 383/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.1393 - mse: 0.1393 - mae: 0.2775 - val_loss: 0.3178 - val_mse: 0.3178 - val_mae: 0.4191\n",
      "Epoch 384/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.1368 - mse: 0.1368 - mae: 0.3055 - val_loss: 0.2508 - val_mse: 0.2508 - val_mae: 0.3873\n",
      "Epoch 385/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.1384 - mse: 0.1384 - mae: 0.2805 - val_loss: 0.3281 - val_mse: 0.3281 - val_mae: 0.4363\n",
      "Epoch 386/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.1436 - mse: 0.1436 - mae: 0.3140 - val_loss: 0.2550 - val_mse: 0.2550 - val_mae: 0.3914\n",
      "Epoch 387/495\n",
      "91/91 [==============================] - 0s 292us/sample - loss: 0.1540 - mse: 0.1540 - mae: 0.3023 - val_loss: 0.3616 - val_mse: 0.3616 - val_mae: 0.4716\n",
      "Epoch 388/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.1725 - mse: 0.1725 - mae: 0.3451 - val_loss: 0.2824 - val_mse: 0.2824 - val_mae: 0.4209\n",
      "Epoch 389/495\n",
      "91/91 [==============================] - 0s 297us/sample - loss: 0.1943 - mse: 0.1943 - mae: 0.3520 - val_loss: 0.4037 - val_mse: 0.4037 - val_mae: 0.5052\n",
      "Epoch 390/495\n",
      "91/91 [==============================] - 0s 263us/sample - loss: 0.2125 - mse: 0.2125 - mae: 0.3784 - val_loss: 0.2972 - val_mse: 0.2972 - val_mae: 0.4427\n",
      "Epoch 391/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.2032 - mse: 0.2032 - mae: 0.3671 - val_loss: 0.3712 - val_mse: 0.3712 - val_mae: 0.4760\n",
      "Epoch 392/495\n",
      "91/91 [==============================] - 0s 317us/sample - loss: 0.1863 - mse: 0.1863 - mae: 0.3519 - val_loss: 0.2763 - val_mse: 0.2763 - val_mae: 0.4091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/495\n",
      "91/91 [==============================] - 0s 313us/sample - loss: 0.1643 - mse: 0.1643 - mae: 0.3313 - val_loss: 0.3268 - val_mse: 0.3268 - val_mae: 0.4458\n",
      "Epoch 394/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.1509 - mse: 0.1509 - mae: 0.3128 - val_loss: 0.2672 - val_mse: 0.2672 - val_mae: 0.3823\n",
      "Epoch 395/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.1426 - mse: 0.1426 - mae: 0.3071 - val_loss: 0.3083 - val_mse: 0.3083 - val_mae: 0.4348\n",
      "Epoch 396/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.1392 - mse: 0.1392 - mae: 0.2945 - val_loss: 0.2746 - val_mse: 0.2746 - val_mae: 0.3803\n",
      "Epoch 397/495\n",
      "91/91 [==============================] - 0s 295us/sample - loss: 0.1408 - mse: 0.1408 - mae: 0.3055 - val_loss: 0.3085 - val_mse: 0.3085 - val_mae: 0.4404\n",
      "Epoch 398/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.1471 - mse: 0.1471 - mae: 0.2920 - val_loss: 0.3144 - val_mse: 0.3144 - val_mae: 0.4039\n",
      "Epoch 399/495\n",
      "91/91 [==============================] - 0s 317us/sample - loss: 0.1639 - mse: 0.1639 - mae: 0.3323 - val_loss: 0.3365 - val_mse: 0.3365 - val_mae: 0.4694\n",
      "Epoch 400/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.1920 - mse: 0.1920 - mae: 0.3365 - val_loss: 0.4121 - val_mse: 0.4121 - val_mae: 0.4718\n",
      "Epoch 401/495\n",
      "91/91 [==============================] - 0s 263us/sample - loss: 0.2255 - mse: 0.2255 - mae: 0.3895 - val_loss: 0.3544 - val_mse: 0.3544 - val_mae: 0.4766\n",
      "Epoch 402/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.2331 - mse: 0.2331 - mae: 0.3768 - val_loss: 0.4002 - val_mse: 0.4002 - val_mae: 0.4654\n",
      "Epoch 403/495\n",
      "91/91 [==============================] - 0s 300us/sample - loss: 0.2020 - mse: 0.2020 - mae: 0.3758 - val_loss: 0.2870 - val_mse: 0.2870 - val_mae: 0.4179\n",
      "Epoch 404/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.1703 - mse: 0.1703 - mae: 0.3125 - val_loss: 0.3340 - val_mse: 0.3340 - val_mae: 0.4202\n",
      "Epoch 405/495\n",
      "91/91 [==============================] - 0s 186us/sample - loss: 0.1476 - mse: 0.1476 - mae: 0.3178 - val_loss: 0.2556 - val_mse: 0.2556 - val_mae: 0.3930\n",
      "Epoch 406/495\n",
      "91/91 [==============================] - 0s 300us/sample - loss: 0.1369 - mse: 0.1369 - mae: 0.2746 - val_loss: 0.3144 - val_mse: 0.3144 - val_mae: 0.4170\n",
      "Epoch 407/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.1323 - mse: 0.1323 - mae: 0.3002 - val_loss: 0.2475 - val_mse: 0.2475 - val_mae: 0.3846\n",
      "Epoch 408/495\n",
      "91/91 [==============================] - 0s 295us/sample - loss: 0.1323 - mse: 0.1323 - mae: 0.2744 - val_loss: 0.3195 - val_mse: 0.3195 - val_mae: 0.4299\n",
      "Epoch 409/495\n",
      "91/91 [==============================] - 0s 295us/sample - loss: 0.1355 - mse: 0.1355 - mae: 0.3043 - val_loss: 0.2490 - val_mse: 0.2490 - val_mae: 0.3837\n",
      "Epoch 410/495\n",
      "91/91 [==============================] - 0s 299us/sample - loss: 0.1429 - mse: 0.1429 - mae: 0.2889 - val_loss: 0.3443 - val_mse: 0.3443 - val_mae: 0.4585\n",
      "Epoch 411/495\n",
      "91/91 [==============================] - 0s 279us/sample - loss: 0.1564 - mse: 0.1564 - mae: 0.3277 - val_loss: 0.2690 - val_mse: 0.2690 - val_mae: 0.4059\n",
      "Epoch 412/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.1748 - mse: 0.1748 - mae: 0.3314 - val_loss: 0.3858 - val_mse: 0.3858 - val_mae: 0.4946\n",
      "Epoch 413/495\n",
      "91/91 [==============================] - 0s 293us/sample - loss: 0.1951 - mse: 0.1951 - mae: 0.3641 - val_loss: 0.2906 - val_mse: 0.2906 - val_mae: 0.4368\n",
      "Epoch 414/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.1958 - mse: 0.1958 - mae: 0.3586 - val_loss: 0.3723 - val_mse: 0.3723 - val_mae: 0.4782\n",
      "Epoch 415/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.1859 - mse: 0.1859 - mae: 0.3522 - val_loss: 0.2748 - val_mse: 0.2748 - val_mae: 0.4118\n",
      "Epoch 416/495\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.1642 - mse: 0.1642 - mae: 0.3296 - val_loss: 0.3281 - val_mse: 0.3281 - val_mae: 0.4443\n",
      "Epoch 417/495\n",
      "91/91 [==============================] - 0s 317us/sample - loss: 0.1499 - mse: 0.1499 - mae: 0.3141 - val_loss: 0.2621 - val_mse: 0.2621 - val_mae: 0.3831\n",
      "Epoch 418/495\n",
      "91/91 [==============================] - 0s 295us/sample - loss: 0.1390 - mse: 0.1390 - mae: 0.3009 - val_loss: 0.3062 - val_mse: 0.3062 - val_mae: 0.4301\n",
      "Epoch 419/495\n",
      "91/91 [==============================] - 0s 273us/sample - loss: 0.1339 - mse: 0.1339 - mae: 0.2925 - val_loss: 0.2628 - val_mse: 0.2628 - val_mae: 0.3736\n",
      "Epoch 420/495\n",
      "91/91 [==============================] - 0s 167us/sample - loss: 0.1325 - mse: 0.1325 - mae: 0.2944 - val_loss: 0.3026 - val_mse: 0.3026 - val_mae: 0.4320\n",
      "Epoch 421/495\n",
      "91/91 [==============================] - 0s 263us/sample - loss: 0.1346 - mse: 0.1346 - mae: 0.2857 - val_loss: 0.2822 - val_mse: 0.2822 - val_mae: 0.3826\n",
      "Epoch 422/495\n",
      "91/91 [==============================] - 0s 339us/sample - loss: 0.1428 - mse: 0.1428 - mae: 0.3074 - val_loss: 0.3167 - val_mse: 0.3167 - val_mae: 0.4521\n",
      "Epoch 423/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.1588 - mse: 0.1588 - mae: 0.3039 - val_loss: 0.3567 - val_mse: 0.3567 - val_mae: 0.4321\n",
      "Epoch 424/495\n",
      "91/91 [==============================] - 0s 293us/sample - loss: 0.1899 - mse: 0.1899 - mae: 0.3587 - val_loss: 0.3578 - val_mse: 0.3578 - val_mae: 0.4834\n",
      "Epoch 425/495\n",
      "91/91 [==============================] - 0s 295us/sample - loss: 0.2247 - mse: 0.2247 - mae: 0.3707 - val_loss: 0.4292 - val_mse: 0.4292 - val_mae: 0.4845\n",
      "Epoch 426/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.2278 - mse: 0.2278 - mae: 0.3969 - val_loss: 0.3145 - val_mse: 0.3145 - val_mae: 0.4425\n",
      "Epoch 427/495\n",
      "91/91 [==============================] - 0s 282us/sample - loss: 0.1988 - mse: 0.1988 - mae: 0.3478 - val_loss: 0.3559 - val_mse: 0.3559 - val_mae: 0.4334\n",
      "Epoch 428/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.1622 - mse: 0.1622 - mae: 0.3350 - val_loss: 0.2593 - val_mse: 0.2593 - val_mae: 0.3960\n",
      "Epoch 429/495\n",
      "91/91 [==============================] - 0s 308us/sample - loss: 0.1417 - mse: 0.1417 - mae: 0.2805 - val_loss: 0.3159 - val_mse: 0.3159 - val_mae: 0.4169\n",
      "Epoch 430/495\n",
      "91/91 [==============================] - 0s 550us/sample - loss: 0.1313 - mse: 0.1313 - mae: 0.2989 - val_loss: 0.2453 - val_mse: 0.2453 - val_mae: 0.3845\n",
      "Epoch 431/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.1277 - mse: 0.1277 - mae: 0.2683 - val_loss: 0.3112 - val_mse: 0.3112 - val_mae: 0.4222\n",
      "Epoch 432/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.1278 - mse: 0.1278 - mae: 0.2947 - val_loss: 0.2436 - val_mse: 0.2436 - val_mae: 0.3794\n",
      "Epoch 433/495\n",
      "91/91 [==============================] - 0s 305us/sample - loss: 0.1313 - mse: 0.1313 - mae: 0.2758 - val_loss: 0.3247 - val_mse: 0.3247 - val_mae: 0.4421\n",
      "Epoch 434/495\n",
      "91/91 [==============================] - 0s 350us/sample - loss: 0.1389 - mse: 0.1389 - mae: 0.3073 - val_loss: 0.2538 - val_mse: 0.2538 - val_mae: 0.3888\n",
      "Epoch 435/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.1513 - mse: 0.1513 - mae: 0.3041 - val_loss: 0.3584 - val_mse: 0.3584 - val_mae: 0.4751\n",
      "Epoch 436/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.1693 - mse: 0.1693 - mae: 0.3403 - val_loss: 0.2776 - val_mse: 0.2776 - val_mae: 0.4207\n",
      "Epoch 437/495\n",
      "91/91 [==============================] - 0s 284us/sample - loss: 0.1812 - mse: 0.1812 - mae: 0.3415 - val_loss: 0.3738 - val_mse: 0.3738 - val_mae: 0.4826\n",
      "Epoch 438/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.1849 - mse: 0.1849 - mae: 0.3523 - val_loss: 0.2761 - val_mse: 0.2761 - val_mae: 0.4180\n",
      "Epoch 439/495\n",
      "91/91 [==============================] - 0s 329us/sample - loss: 0.1699 - mse: 0.1699 - mae: 0.3333 - val_loss: 0.3382 - val_mse: 0.3382 - val_mae: 0.4502\n",
      "Epoch 440/495\n",
      "91/91 [==============================] - 0s 258us/sample - loss: 0.1560 - mse: 0.1560 - mae: 0.3221 - val_loss: 0.2606 - val_mse: 0.2606 - val_mae: 0.3895\n",
      "Epoch 441/495\n",
      "91/91 [==============================] - 0s 284us/sample - loss: 0.1412 - mse: 0.1412 - mae: 0.3021 - val_loss: 0.3094 - val_mse: 0.3094 - val_mae: 0.4292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442/495\n",
      "91/91 [==============================] - 0s 299us/sample - loss: 0.1333 - mse: 0.1333 - mae: 0.2942 - val_loss: 0.2549 - val_mse: 0.2549 - val_mae: 0.3740\n",
      "Epoch 443/495\n",
      "91/91 [==============================] - 0s 275us/sample - loss: 0.1281 - mse: 0.1281 - mae: 0.2861 - val_loss: 0.3000 - val_mse: 0.3000 - val_mae: 0.4244\n",
      "Epoch 444/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.1267 - mse: 0.1267 - mae: 0.2840 - val_loss: 0.2590 - val_mse: 0.2590 - val_mae: 0.3689\n",
      "Epoch 445/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.1281 - mse: 0.1281 - mae: 0.2882 - val_loss: 0.3038 - val_mse: 0.3038 - val_mae: 0.4339\n",
      "Epoch 446/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.1328 - mse: 0.1328 - mae: 0.2841 - val_loss: 0.2840 - val_mse: 0.2840 - val_mae: 0.3809\n",
      "Epoch 447/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.1441 - mse: 0.1441 - mae: 0.3081 - val_loss: 0.3226 - val_mse: 0.3226 - val_mae: 0.4581\n",
      "Epoch 448/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.1636 - mse: 0.1636 - mae: 0.3134 - val_loss: 0.3731 - val_mse: 0.3731 - val_mae: 0.4427\n",
      "Epoch 449/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.1991 - mse: 0.1991 - mae: 0.3666 - val_loss: 0.3590 - val_mse: 0.3590 - val_mae: 0.4842\n",
      "Epoch 450/495\n",
      "91/91 [==============================] - 0s 300us/sample - loss: 0.2308 - mse: 0.2308 - mae: 0.3786 - val_loss: 0.4229 - val_mse: 0.4229 - val_mae: 0.4827\n",
      "Epoch 451/495\n",
      "91/91 [==============================] - 0s 297us/sample - loss: 0.2171 - mse: 0.2171 - mae: 0.3882 - val_loss: 0.2943 - val_mse: 0.2943 - val_mae: 0.4253\n",
      "Epoch 452/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.1810 - mse: 0.1810 - mae: 0.3315 - val_loss: 0.3414 - val_mse: 0.3414 - val_mae: 0.4280\n",
      "Epoch 453/495\n",
      "91/91 [==============================] - 0s 282us/sample - loss: 0.1479 - mse: 0.1479 - mae: 0.3183 - val_loss: 0.2493 - val_mse: 0.2493 - val_mae: 0.3894\n",
      "Epoch 454/495\n",
      "91/91 [==============================] - 0s 317us/sample - loss: 0.1316 - mse: 0.1316 - mae: 0.2702 - val_loss: 0.3086 - val_mse: 0.3086 - val_mae: 0.4161\n",
      "Epoch 455/495\n",
      "91/91 [==============================] - 0s 351us/sample - loss: 0.1241 - mse: 0.1241 - mae: 0.2901 - val_loss: 0.2405 - val_mse: 0.2405 - val_mae: 0.3797\n",
      "Epoch 456/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.1220 - mse: 0.1220 - mae: 0.2637 - val_loss: 0.3062 - val_mse: 0.3062 - val_mae: 0.4228\n",
      "Epoch 457/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.1233 - mse: 0.1233 - mae: 0.2881 - val_loss: 0.2414 - val_mse: 0.2414 - val_mae: 0.3755\n",
      "Epoch 458/495\n",
      "91/91 [==============================] - 0s 295us/sample - loss: 0.1277 - mse: 0.1277 - mae: 0.2718 - val_loss: 0.3217 - val_mse: 0.3217 - val_mae: 0.4436\n",
      "Epoch 459/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.1366 - mse: 0.1366 - mae: 0.3043 - val_loss: 0.2536 - val_mse: 0.2536 - val_mae: 0.3892\n",
      "Epoch 460/495\n",
      "91/91 [==============================] - 0s 329us/sample - loss: 0.1489 - mse: 0.1489 - mae: 0.3027 - val_loss: 0.3532 - val_mse: 0.3532 - val_mae: 0.4721\n",
      "Epoch 461/495\n",
      "91/91 [==============================] - 0s 295us/sample - loss: 0.1645 - mse: 0.1645 - mae: 0.3350 - val_loss: 0.2724 - val_mse: 0.2724 - val_mae: 0.4161\n",
      "Epoch 462/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.1712 - mse: 0.1712 - mae: 0.3325 - val_loss: 0.3590 - val_mse: 0.3590 - val_mae: 0.4700\n",
      "Epoch 463/495\n",
      "91/91 [==============================] - 0s 289us/sample - loss: 0.1710 - mse: 0.1710 - mae: 0.3390 - val_loss: 0.2668 - val_mse: 0.2668 - val_mae: 0.4060\n",
      "Epoch 464/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.1562 - mse: 0.1562 - mae: 0.3176 - val_loss: 0.3267 - val_mse: 0.3267 - val_mae: 0.4406\n",
      "Epoch 465/495\n",
      "91/91 [==============================] - 0s 316us/sample - loss: 0.1446 - mse: 0.1446 - mae: 0.3096 - val_loss: 0.2538 - val_mse: 0.2538 - val_mae: 0.3823\n",
      "Epoch 466/495\n",
      "91/91 [==============================] - 0s 330us/sample - loss: 0.1325 - mse: 0.1325 - mae: 0.2903 - val_loss: 0.3041 - val_mse: 0.3041 - val_mae: 0.4239\n",
      "Epoch 467/495\n",
      "91/91 [==============================] - 0s 350us/sample - loss: 0.1265 - mse: 0.1265 - mae: 0.2865 - val_loss: 0.2488 - val_mse: 0.2488 - val_mae: 0.3697\n",
      "Epoch 468/495\n",
      "91/91 [==============================] - 0s 300us/sample - loss: 0.1224 - mse: 0.1224 - mae: 0.2767 - val_loss: 0.2989 - val_mse: 0.2989 - val_mae: 0.4219\n",
      "Epoch 469/495\n",
      "91/91 [==============================] - 0s 305us/sample - loss: 0.1217 - mse: 0.1217 - mae: 0.2798 - val_loss: 0.2502 - val_mse: 0.2502 - val_mae: 0.3639\n",
      "Epoch 470/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.1230 - mse: 0.1230 - mae: 0.2792 - val_loss: 0.3056 - val_mse: 0.3056 - val_mae: 0.4324\n",
      "Epoch 471/495\n",
      "91/91 [==============================] - 0s 330us/sample - loss: 0.1267 - mse: 0.1267 - mae: 0.2813 - val_loss: 0.2629 - val_mse: 0.2629 - val_mae: 0.3674\n",
      "Epoch 472/495\n",
      "91/91 [==============================] - 0s 292us/sample - loss: 0.1333 - mse: 0.1333 - mae: 0.2957 - val_loss: 0.3160 - val_mse: 0.3160 - val_mae: 0.4482\n",
      "Epoch 473/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.1421 - mse: 0.1421 - mae: 0.2949 - val_loss: 0.3099 - val_mse: 0.3099 - val_mae: 0.3959\n",
      "Epoch 474/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.1604 - mse: 0.1604 - mae: 0.3287 - val_loss: 0.3383 - val_mse: 0.3383 - val_mae: 0.4736\n",
      "Epoch 475/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.1918 - mse: 0.1918 - mae: 0.3453 - val_loss: 0.4302 - val_mse: 0.4302 - val_mae: 0.4833\n",
      "Epoch 476/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.2291 - mse: 0.2291 - mae: 0.3925 - val_loss: 0.3360 - val_mse: 0.3360 - val_mae: 0.4613\n",
      "Epoch 477/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.2242 - mse: 0.2242 - mae: 0.3796 - val_loss: 0.3800 - val_mse: 0.3800 - val_mae: 0.4542\n",
      "Epoch 478/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.1760 - mse: 0.1760 - mae: 0.3499 - val_loss: 0.2574 - val_mse: 0.2574 - val_mae: 0.3953\n",
      "Epoch 479/495\n",
      "91/91 [==============================] - 0s 282us/sample - loss: 0.1427 - mse: 0.1427 - mae: 0.2851 - val_loss: 0.3114 - val_mse: 0.3114 - val_mae: 0.4169\n",
      "Epoch 480/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.1247 - mse: 0.1247 - mae: 0.2913 - val_loss: 0.2391 - val_mse: 0.2391 - val_mae: 0.3807\n",
      "Epoch 481/495\n",
      "91/91 [==============================] - 0s 285us/sample - loss: 0.1172 - mse: 0.1172 - mae: 0.2547 - val_loss: 0.2958 - val_mse: 0.2958 - val_mae: 0.4135\n",
      "Epoch 482/495\n",
      "91/91 [==============================] - 0s 298us/sample - loss: 0.1151 - mse: 0.1151 - mae: 0.2765 - val_loss: 0.2374 - val_mse: 0.2374 - val_mae: 0.3735\n",
      "Epoch 483/495\n",
      "91/91 [==============================] - 0s 306us/sample - loss: 0.1162 - mse: 0.1162 - mae: 0.2574 - val_loss: 0.3022 - val_mse: 0.3022 - val_mae: 0.4270\n",
      "Epoch 484/495\n",
      "91/91 [==============================] - 0s 317us/sample - loss: 0.1208 - mse: 0.1208 - mae: 0.2834 - val_loss: 0.2421 - val_mse: 0.2421 - val_mae: 0.3738\n",
      "Epoch 485/495\n",
      "91/91 [==============================] - 0s 328us/sample - loss: 0.1282 - mse: 0.1282 - mae: 0.2753 - val_loss: 0.3253 - val_mse: 0.3253 - val_mae: 0.4504\n",
      "Epoch 486/495\n",
      "91/91 [==============================] - 0s 310us/sample - loss: 0.1396 - mse: 0.1396 - mae: 0.3082 - val_loss: 0.2560 - val_mse: 0.2560 - val_mae: 0.3941\n",
      "Epoch 487/495\n",
      "91/91 [==============================] - 0s 307us/sample - loss: 0.1505 - mse: 0.1505 - mae: 0.3072 - val_loss: 0.3506 - val_mse: 0.3506 - val_mae: 0.4682\n",
      "Epoch 488/495\n",
      "91/91 [==============================] - 0s 275us/sample - loss: 0.1608 - mse: 0.1608 - mae: 0.3303 - val_loss: 0.2652 - val_mse: 0.2652 - val_mae: 0.4085\n",
      "Epoch 489/495\n",
      "91/91 [==============================] - 0s 313us/sample - loss: 0.1589 - mse: 0.1589 - mae: 0.3196 - val_loss: 0.3408 - val_mse: 0.3408 - val_mae: 0.4520\n",
      "Epoch 490/495\n",
      "91/91 [==============================] - 0s 296us/sample - loss: 0.1535 - mse: 0.1535 - mae: 0.3215 - val_loss: 0.2554 - val_mse: 0.2554 - val_mae: 0.3912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 491/495\n",
      "91/91 [==============================] - 0s 318us/sample - loss: 0.1394 - mse: 0.1394 - mae: 0.2967 - val_loss: 0.3127 - val_mse: 0.3127 - val_mae: 0.4279\n",
      "Epoch 492/495\n",
      "91/91 [==============================] - 0s 309us/sample - loss: 0.1307 - mse: 0.1307 - mae: 0.2932 - val_loss: 0.2458 - val_mse: 0.2458 - val_mae: 0.3738\n",
      "Epoch 493/495\n",
      "91/91 [==============================] - 0s 275us/sample - loss: 0.1223 - mse: 0.1223 - mae: 0.2754 - val_loss: 0.2990 - val_mse: 0.2990 - val_mae: 0.4195\n",
      "Epoch 494/495\n",
      "91/91 [==============================] - 0s 312us/sample - loss: 0.1188 - mse: 0.1188 - mae: 0.2778 - val_loss: 0.2416 - val_mse: 0.2416 - val_mae: 0.3650\n",
      "Epoch 495/495\n",
      "91/91 [==============================] - 0s 336us/sample - loss: 0.1168 - mse: 0.1168 - mae: 0.2678 - val_loss: 0.3020 - val_mse: 0.3020 - val_mae: 0.4245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a8e7dcbd68>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_features, # Features\n",
    "                      train_target, # Target vector\n",
    "                      epochs=495, # Number of epochs\n",
    "                      verbose=1, # No output\n",
    "                      batch_size=100, # Number of observations per batch\n",
    "                      validation_data=(test_features, test_target)) # Data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.505841 ],\n",
       "       [4.5979657],\n",
       "       [4.5847483],\n",
       "       [5.2887874],\n",
       "       [4.402303 ],\n",
       "       [4.574259 ],\n",
       "       [4.7269287],\n",
       "       [4.436658 ],\n",
       "       [4.279626 ],\n",
       "       [4.8955407],\n",
       "       [4.728228 ],\n",
       "       [4.9222655],\n",
       "       [4.882103 ],\n",
       "       [4.6261287],\n",
       "       [4.128306 ],\n",
       "       [4.890925 ],\n",
       "       [4.688026 ],\n",
       "       [4.7564416],\n",
       "       [4.573081 ],\n",
       "       [4.564682 ],\n",
       "       [4.7745485],\n",
       "       [4.39351  ],\n",
       "       [4.6317177],\n",
       "       [4.4784164],\n",
       "       [3.9800248],\n",
       "       [4.1079993],\n",
       "       [4.7103214],\n",
       "       [4.449535 ],\n",
       "       [5.018085 ],\n",
       "       [4.662338 ],\n",
       "       [4.937296 ],\n",
       "       [4.627944 ],\n",
       "       [4.6411037],\n",
       "       [4.649838 ],\n",
       "       [4.5338106],\n",
       "       [4.2394423],\n",
       "       [4.705721 ],\n",
       "       [5.167671 ],\n",
       "       [4.4171457],\n",
       "       [4.5422826],\n",
       "       [5.035649 ],\n",
       "       [4.7475686],\n",
       "       [4.440301 ],\n",
       "       [4.7431917],\n",
       "       [4.5276346],\n",
       "       [5.163328 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.9, 4.5, 4.6, 4.9, 4. , 4. , 4.1, 4.4, 6. , 4.6, 4.5, 4.4, 4.1,\n",
       "       3.9, 4.5, 4.3, 4.6, 4.7, 4.8, 4.3, 3.9, 4.4, 4.9, 5. , 4.3, 3.8,\n",
       "       4.1, 4. , 4.7, 4. , 4. , 5.6, 5. , 4.7, 4.8, 4.6, 4.1, 3.8, 4.3,\n",
       "       4.5, 4.6, 4.1, 4.4, 4.6, 4.7, 4.9])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yamin\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ANN1st.model\\assets\n"
     ]
    }
   ],
   "source": [
    "network.save('ANN1st.model')\n",
    "network.save_weights('ANN1st.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network.predict([[2.0,3.0,75.0]])\n",
    "a1 = network.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 =test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9   [4.4]\n",
      "4.5   [4.1]\n",
      "4.6   [4.3]\n",
      "4.9   [5.3]\n",
      "4.0   [4.3]\n",
      "4.0   [4.2]\n",
      "4.1   [4.7]\n",
      "4.4   [4.2]\n",
      "6.0   [4.3]\n",
      "4.6   [4.8]\n",
      "4.5   [4.2]\n",
      "4.4   [4.8]\n",
      "4.1   [4.6]\n",
      "3.9   [4.2]\n",
      "4.5   [3.6]\n",
      "4.3   [4.8]\n",
      "4.6   [4.6]\n",
      "4.7   [4.7]\n",
      "4.8   [4.9]\n",
      "4.3   [4.1]\n",
      "3.9   [4.2]\n",
      "4.4   [4.]\n",
      "4.9   [4.7]\n",
      "5.0   [4.4]\n",
      "4.3   [4.3]\n",
      "3.8   [3.8]\n",
      "4.1   [4.2]\n",
      "4.0   [4.]\n",
      "4.7   [5.1]\n",
      "4.0   [4.2]\n",
      "4.0   [4.2]\n",
      "5.6   [4.4]\n",
      "5.0   [4.9]\n",
      "4.7   [4.5]\n",
      "4.8   [4.3]\n",
      "4.6   [4.5]\n",
      "4.1   [4.5]\n",
      "3.8   [4.9]\n",
      "4.3   [4.4]\n",
      "4.5   [4.6]\n",
      "4.6   [5.3]\n",
      "4.1   [4.2]\n",
      "4.4   [4.2]\n",
      "4.6   [4.8]\n",
      "4.7   [4.2]\n",
      "4.9   [5.2]\n",
      "0.23434781779415975\n",
      "0.3521739223729009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# real value\n",
    "TP=0\n",
    "FP=0\n",
    "a1=np.round_(a1,decimals = 1)\n",
    "for i in range(0,len(a1)):\n",
    "    print(a2[i],\" \",a1[i])\n",
    "errors = mean_squared_error(a2, a1)\n",
    "print(errors)\n",
    "print(mean_absolute_error(a2,a1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
